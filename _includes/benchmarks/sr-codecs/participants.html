<h3>Super-resolution models</h3>
<div id="comm_comp_div" class="datatable-container">
    <div class="datatable-center">
        <table id="char_table" class="display" style="width:99%">
            <thead>
                <tr>
                    <th style="background-color: #3d6f96; color: #ffffff">Name</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Video/Image SR</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Implementation</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Paper</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Year</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Added by</th>
                </tr>
            </thead>
            <tbody>
                <tr class="item">
                    <td>bicubic<sup>*</sup></td>
                    <td>—</td>
                    <td>—</td>
                    <td>—</td>
                    <td>—</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>only compressed<sup>**</sup></td>
                    <td>—</td>
                    <td>—</td>
                    <td>—</td>
                    <td>—</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>RSDN</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/junpan19/RSDN">Link</a></td>
                    <td><a href="https://arxiv.org/pdf/2008.00455.pdf">Link</a></td>
                    <td>2020</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>COMISR</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/google-research/google-research/tree/master/comisr">Link</a></td>
                    <td><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Li_COMISR_Compression-Informed_Video_Super-Resolution_ICCV_2021_paper.pdf">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>TMNet</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/CS-GangXu/TMNet">Link</a></td>
                    <td><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Temporal_Modulation_Network_for_Controllable_Space-Time_Video_Super-Resolution_CVPR_2021_paper.pdf">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>SwinIR</td>
                    <td style="color: #d11d12">ISR</td>
                    <td><a href="https://github.com/JingyunLiang/SwinIR">Link</a></td>
                    <td><a href="https://openaccess.thecvf.com/content/ICCV2021W/AIM/papers/Liang_SwinIR_Image_Restoration_Using_Swin_Transformer_ICCVW_2021_paper.pdf">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>BasicVSR</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/xinntao/BasicSR">Link</a></td>
                    <td><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Chan_BasicVSR_The_Search_for_Essential_Components_in_Video_Super-Resolution_and_CVPR_2021_paper.pdf">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>RBPN</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/alterzero/RBPN-PyTorch">Link</a></td>
                    <td><a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Haris_Recurrent_Back-Projection_Network_for_Video_Super-Resolution_CVPR_2019_paper.pdf">Link</a></td>
                    <td>2019</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>VRT</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/JingyunLiang/VRT">Link</a></td>
                    <td><a href="https://arxiv.org/pdf/2201.12288.pdf">Link</a></td>
                    <td>2022</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>DBVSR</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/cscss/DBVSR">Link</a></td>
                    <td><a href="https://arxiv.org/abs/2003.04716">Link</a></td>
                    <td>2020</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>LGFN</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/BIOINSu/LGFN">Link</a></td>
                    <td><a href="https://doi.org/10.1109/ACCESS.2020.3025780">Link</a></td>
                    <td>2020</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>SOF-VSR-BD</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/LongguangWang/SOF-VSR">Link</a></td>
                    <td><a href="https://doi.org/10.1109/TIP.2020.2967596">Link</a></td>
                    <td>2020</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>SOF-VSR-BI</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/LongguangWang/SOF-VSR">Link</a></td>
                    <td><a href="https://doi.org/10.1109/TIP.2020.2967596">Link</a></td>
                    <td>2020</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>EGVSR</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://github.com/Thmen/EGVSR">Link</a></td>
                    <td><a href="https://arxiv.org/ftp/arxiv/papers/2107/2107.05307.pdf">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>amq-12</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://www.topazlabs.com/video-enhance-ai">Link</a></td>
                    <td>—</td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>ahq-11</td>
                    <td style="color: #218838">VSR</td>
                    <td><a href="https://www.topazlabs.com/video-enhance-ai">Link</a></td>
                    <td>—</td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>RealSR</td>
                    <td style="color: #d11d12">ISR</td>
                    <td><a href="https://github.com/jixiaozhong/RealSR">Link</a></td>
                    <td><a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w31/Ji_Real-World_Super-Resolution_via_Kernel_Estimation_and_Noise_Injection_CVPRW_2020_paper.pdf">Link</a></td>
                    <td>2020</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>Real-ESRGAN</td>
                    <td style="color: #d11d12">ISR</td>
                    <td><a href="https://github.com/xinntao/Real-ESRGAN">Link</a></td>
                    <td><a href="https://arxiv.org/abs/2107.10833">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>  
            </tbody>
        </table>
        
        
        
        <script>$(document).ready(function () {
            $('#char_table').DataTable({
                lengthChange: false,
                paging: false,
                searching: false
            });
        });</script>
    </div>
</div>

<h3 id="codecs_table">Video codecs that use super-resolution in decoder</h3>
<div id="comm_comp_div" class="datatable-container">
    <div class="datatable-center">
        <table id="char_table2" class="display" style="width:99%">
            <thead>
                <tr>
                    <th style="background-color: #3d6f96; color: #ffffff">Name</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Implementation</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Paper</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Year</th>
                    <th style="background-color: #3d6f96; color: #ffffff">Added by</th>
                </tr>
            </thead>
            <tbody>
                <tr class="item">
                    <td>ViSTRA2</td>
                    <td><a href="https://fan-aaron-zhang.github.io/ViSTRA/">Link</a></td>
                    <td><a href="https://arxiv.org/pdf/1911.02833.pdf">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>RR-DnCNN</td>
                    <td><a href="https://minhmanho.github.io/rrdncnn/">Link</a></td>
                    <td><a href="https://link.springer.com/chapter/10.1007/978-3-030-37731-1_9">Link</a></td>
                    <td>2020</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>RR-DnCNN v2.0<sup>***</sup></td>
                    <td><a href="https://minhmanho.github.io/rrdncnn/">Link</a></td>
                    <td><a href="https://arxiv.org/ftp/arxiv/papers/2002/2002.10739.pdf">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>SRVC</td>
                    <td><a href=" https://github.com/AdaptiveVC/SRVC.git">Link</a></td>
                    <td><a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Khani_Efficient_Video_Compression_via_Content-Adaptive_Super-Resolution_ICCV_2021_paper.pdf">Link</a></td>
                    <td>2021</td>
                    <td>MSU</td>
                </tr>
                <tr class="item">
                    <td>SVT-AV1</td>
                    <td><a href="https://gitlab.com/AOMediaCodec/SVT-AV1">Link</a></td>
                    <td>—</td>
                    <td>2020</td>
                    <td>MSU</td>
                </tr>
            </tbody>
        </table>
        
        
        
        <script>$(document).ready(function () {
            $('#char_table2').DataTable({
                lengthChange: false,
                paging: false,
                searching: false
            });
        });</script>
    </div>
</div>


<p>
    * We use the following FFmpeg command:<br> <code>ffmpeg -i {input_video} -vf scale=1920:1080 -sws_flags bicubic {output_directory}/frame%04d.png</code>
</p>
<p>
    ** To get only compressed results, we compress input video without downsampling. You can see the list of codecs <a href="/benchmarks/super-resolution-for-video-compression-methodology.html#codecs">here</a>.
</p>
<p>
    *** Improved RR-DnCNN model
</p>
<!--
<h2 id="dbvsr">DBVSR</h2>
<ul>Estimates a motion blur for the particular input. Compensates the motion between frames explicitly.</ul>
<div class="center">
	<div>
		<img src="/assets/img/benchmarks/sr-codecs/dbvsr.jpg">
	</div>
</div>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://github.com/cscss/DBVSR">GitHub</a>, <a href="https://arxiv.org/abs/2003.04716">paper</a></ul>

<h2 id="dynavsr">DynaVSR</h2>
<ul>DynaVSR can be applied to any VSR deep-learning model. For our benchmark, we used pretrained weights for model EDVR, which uses Deformable convolution to align neighboring frames.</ul>
<div class="center">
	<div>
		<img src="/assets/img/benchmarks/sr-codecs/dynavsr.jpg">
	</div>
</div>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://github.com/esw0116/DynaVSR">GitHub</a>, <a href="http://arxiv.org/abs/2011.04482">paper</a></ul>

<h2 id="egvsr">EGVSR</h2>
<ul>The generator part 
    is  divided  into  FNet  module  and  SRNet  module  for  optical 
    flow estimation and video frame super-resolution, 
    respectively.</ul>
<div class="center">
	<div>
		<img src="/assets/img/benchmarks/sr-codecs/egvsr.png">
	</div>
</div>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://github.com/Thmen/EGVSR">GitHub</a>, <a href="https://arxiv.org/ftp/arxiv/papers/2107/2107.05307.pdf">paper</a></ul>

<h2 id="iSeeBetter">iSeeBetter</h2>
<ul>A combination of an RNN-based optical flow method that preserves spatio-temporal information in the current and adjacent frames as the generator and a discriminator that is adept at ensuring the generated SR frame offers superior fidelity.</ul>
<div class="center">
	<div>
		<img src="/assets/img/benchmarks/sr-codecs/iseebetter.png">
	</div>
</div>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://github.com/amanchadha/iSeeBetter">GitHub</a>, <a href="https://arxiv.org/pdf/2006.11161.pdf">paper</a></ul>

<h2 id="lgfn">LGFN</h2>
<ul>Uses deformable convolutions with decreased multi-dilation convolution units (DMDCUs) to align frames explicitly. Fuses features from local and global fusion modules.</ul>
<div class="center">
	<div>
		<img src="/assets/img/benchmarks/sr-codecs/lgfn.jpg">
	</div>
</div>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://github.com/BIOINSu/LGFN">GitHub</a>, <a href="https://doi.org/10.1109/ACCESS.2020.3025780">paper</a></ul>

<h2 id="realsr">RealSR</h2>
<ul>Tries to estimate degradation kernel and noise distribution for better visual quality.</ul>
<div class="center">
	<div style="width:75%">
		<img src="/assets/img/benchmarks/sr-codecs/realsr.jpg">
	</div>
</div>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://github.com/nihui/realsr-ncnn-vulkan">GitHub</a>, <a href="https://github.com/jixiaozhong/RealSR">GitHub</a>, <a href="https://doi.org/10.1109/CVPRW50498.2020.00241">paper</a></ul>

<h2 id="sof-vsr">SOF-VSR</h2>
<ul>Two models: SOF-VSR-BD (trained on gauss degradation type), SOF-VSR-BI (trained on bicubic degradation type)</ul>
<ul>Compensates motion by high-resolution optical flow, estimated from the low-resolution one in a coarse-to-fine manner.</ul>
<div class="center">
	<div style="width:75%">
		<img src="/assets/img/benchmarks/sr-codecs/sof-vsr.jpg">
	</div>
</div>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://github.com/LongguangWang/SOF-VSR">GitHub</a>, <a href="https://doi.org/10.1109/TIP.2020.2967596">paper</a></ul>

<h2 id="topaz">Topaz Video Enhance AI</h2>
<ul>Topaz Video Enhance AI is a commercial filter.</ul>
<ul>Three models: 
        <li>ahq-11 (Artemis High Quality v11) - upscale or sharpen high quality input video, reducing motion flicker, </li>
        <li>amq-12 (Artemis Medium Quality v12) - upscale or enhance medium quality video with moderate noise or compression artifacts, </li>
        <li>amqs-1 (Artemis Dehalo v1) - upscale or enhance medium quality progressive video that contains haloing, moderate noise or compression artifacts.</li></ul>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://www.topazlabs.com/video-enhance-ai">Website</a></ul>

<h2 id="waifu2x">waifu2x-ncnn-vulkan</h2>
<ul>Two models: waifu2x-anime and waifu2x-cunet</ul>
<ul>NCNN implementation of waifu2x converter. 
    Waifu2x-ncnn-vulkan uses <a href="https://github.com/Tencent/ncnn">NCNN project</a> as the universal neural network inference framework.
</ul>
<ul>Added to the benchmark by MSU G&M Lab</ul>
<ul>Links: <a href="https://github.com/nihui/waifu2x-ncnn-vulkan">GitHub</a>, <a href="https://github.com/nagadomi/waifu2x">GitHub</a></ul>
-->