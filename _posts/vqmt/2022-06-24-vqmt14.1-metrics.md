---
title: "MSU Video Quality Measurement Tool: Usage of VQMT metrics in CLI"
description: "VQMT 14.1 Online help: Description of VQMT metrics, their parameters and using in CLI"
preview_img: /assets/img/vqmt/online-help/cover.svg
permalink: /vqmt/online-help-14-1/metrics/
hidden: true
tag: []
exclude_from_see_also: true
COMMENT: this file is generated by VQMT with options -list md
---
This is part of MSU Video Quality Measurement tool Online Help for **MSU VQMT 14.1**

{% include vqmt/menu.md %}

Online help for MSU VQMT 14.1 contents:

* [Command-line help](../help/)
* [VQMT various lists and tables](../info/)
* **Usage of VQMT metrics in CLI**
* [Picture types](../picture-types/)
* [Configuration description](../config/)
* [PDF Documenation](https://download.compression.ru/vqmt/doc/MSU_VQMT_Documentation_14-1.pdf)
* [List of documentation pages for all versions](../../vqmt-doc-toc/)


# Content
* TOC
{:toc}
## List of available metrics


#### psnr
**PSNR**  
  
[https://videoprocessing.ai/vqmt/metrics/#psnr](https://videoprocessing.ai/vqmt/metrics/#psnr/)    
* _Color components:_ Y, U, V, R, G, B, LUV-L, RGB, YUV    
* _Type:_ reference metric    
* _Usage:_ `-metr psnr` [over &lt;color component&gt;]    


#### identity
**Identity**  
  
[https://videoprocessing.ai/vqmt/metrics/#identity](https://videoprocessing.ai/vqmt/metrics/#identity/)    
* _Color components:_ Y, U, V, R, G, B, LUV-L, RGB, YUV    
* _Type:_ reference metric    
* _Usage:_ `-metr identity` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Mode    
  Possible types:    
    * binary - 1 images are similar, 0 in other case    
    * pixels - proportion of similar pixels, 1 - all pixels are same (0..1)    
  _Default value:_ `binary`    
  _Usage:_ `-set "mode=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `binary`    
  * `pixels`    


#### ssim
**SSIM**  
  
[https://videoprocessing.ai/vqmt/metrics/#ssim](https://videoprocessing.ai/vqmt/metrics/#ssim/)    
* _Color components:_ Y, U, V, R, G, B, LUV-L, RGB, YUV    
* _Type:_ reference metric    
* _Usage:_ `-metr ssim` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Combining mode    
  The mode of combining values for components of image:    
    * default - in case of YUV image custom weight for Y component will be used, equal weights for U, V components will be used. In case if other color models equvivalent weights will be used    
    * ffmpeg - use area of component. Weights will depend on subsampling mode of image    
  _Default value:_ `default`    
  _Usage:_ `-set "combining_mode=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `ffmpeg`    
* Y weight    
  If combining mode is default this is weight of value for component Y of YUV. Weights of U, V and other components is supposes to be 1.    
  _Default value:_ `4.0000000000000000`    
  _Usage:_ `-set "y_weight=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * 0.00000000000000000    
  * 999999.00000000000    
* _Usage:_ `-metr ssim_fast` [over &lt;color component&gt;]    
* _Usage:_ `-metr ssim_precise` [over &lt;color component&gt;]    
* _Usage:_ `-metr ssim_gpu_id` [over &lt;color component&gt;]    
* _Color components:_ Y, U, V    
* _Usage:_ `-metr ssim_cuda` [over &lt;color component&gt;]    
* _Color components:_ Y, U, V, R, G, B, LUV-L, RGB, YUV    
* _Usage:_ `-metr ssim` [over &lt;color component&gt;] `-dev OpenCL0`    
  
This metric can be configured using next parameter(s):    
* Combining mode    
  The mode of combining values for components of image:    
    * default - in case of YUV image custom weight for Y component will be used, equal weights for U, V components will be used. In case if other color models equvivalent weights will be used    
    * ffmpeg - use area of component. Weights will depend on subsampling mode of image    
  _Default value:_ `default`    
  _Usage:_ `-set "combining_mode=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `ffmpeg`    
* Y weight    
  If combining mode is default this is weight of value for component Y of YUV. Weights of U, V and other components is supposes to be 1.    
  _Default value:_ `4.0000000000000000`    
  _Usage:_ `-set "y_weight=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * 0.00000000000000000    
  * 999999.00000000000    


#### msssim
**MS-SSIM**  
  
[https://videoprocessing.ai/vqmt/metrics/#msssim](https://videoprocessing.ai/vqmt/metrics/#msssim/)    
* _Color components:_ Y, U, V, R, G, B, LUV-L, RGB, YUV    
* _Type:_ reference metric    
* _Usage:_ `-metr msssim` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Combining mode    
  The mode of combining values for components of image:    
    * default - in case of YUV image custom weight for Y component will be used, equal weights for U, V components will be used. In case if other color models equvivalent weights will be used    
    * ffmpeg - use area of component. Weights will depend on subsampling mode of image    
  _Default value:_ `default`    
  _Usage:_ `-set "combining_mode=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `ffmpeg`    
* Y weight    
  If combining mode is default this is weight of value for component Y of YUV. Weights of U, V and other components is supposes to be 1.    
  _Default value:_ `4.0000000000000000`    
  _Usage:_ `-set "y_weight=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * 0.00000000000000000    
  * 999999.00000000000    
[https://videoprocessing.ai/vqmt/metrics/#ssim](https://videoprocessing.ai/vqmt/metrics/#ssim/)    
* _Usage:_ `-metr msssim_fast` [over &lt;color component&gt;]    
[https://videoprocessing.ai/vqmt/metrics/#msssim](https://videoprocessing.ai/vqmt/metrics/#msssim/)    
* _Usage:_ `-metr msssim_precise` [over &lt;color component&gt;]    
* _Color components:_ Y, U, V    
* _Usage:_ `-metr msssim_cuda` [over &lt;color component&gt;]    
* _Color components:_ Y, U, V, R, G, B, LUV-L, RGB, YUV    
* _Usage:_ `-metr msssim` [over &lt;color component&gt;] `-dev OpenCL0`    
  
This metric can be configured using next parameter(s):    
* Combining mode    
  The mode of combining values for components of image:    
    * default - in case of YUV image custom weight for Y component will be used, equal weights for U, V components will be used. In case if other color models equvivalent weights will be used    
    * ffmpeg - use area of component. Weights will depend on subsampling mode of image    
  _Default value:_ `default`    
  _Usage:_ `-set "combining_mode=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `ffmpeg`    
* Y weight    
  If combining mode is default this is weight of value for component Y of YUV. Weights of U, V and other components is supposes to be 1.    
  _Default value:_ `4.0000000000000000`    
  _Usage:_ `-set "y_weight=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * 0.00000000000000000    
  * 999999.00000000000    


#### 3ssim
**3SSIM**  
  
[https://videoprocessing.ai/vqmt/metrics/#3ssim](https://videoprocessing.ai/vqmt/metrics/#3ssim/)    
* _Color components:_ Y, U, V    
* _Type:_ reference metric    
* _Usage:_ `-metr 3ssim` [over &lt;color component&gt;]    
* _Usage:_ `-metr 3ssim_cuda` [over &lt;color component&gt;]    
* _Usage:_ `-metr 3ssim` [over &lt;color component&gt;] `-dev OpenCL0`    


#### vqm
**VQM**  
  
[https://videoprocessing.ai/vqmt/metrics/#vqm](https://videoprocessing.ai/vqmt/metrics/#vqm/)    
* _Color components:_ Y    
* _Type:_ reference metric    
* _Usage:_ `-metr vqm` [over &lt;color component&gt;]    


#### blocking
**Blocking**  
  
[https://videoprocessing.ai/vqmt/metrics/#blockingmeasure](https://videoprocessing.ai/vqmt/metrics/#blockingmeasure/)    
* _Color components:_ Y    
* _Type:_ no-reference metric    
* _Usage:_ `-metr blocking` [over &lt;color component&gt;]    


#### blurring
**Blurring**  
  
[https://videoprocessing.ai/vqmt/metrics/#ybluringmeasure](https://videoprocessing.ai/vqmt/metrics/#ybluringmeasure/)    
* _Color components:_ Y, R, G, B    
* _Type:_ no-reference metric    
* _Usage:_ `-metr blurring` [over &lt;color component&gt;]    
* _Color components:_ Y, U, V, R, G, B    
* _Usage:_ `-metr blurring_delta` [over &lt;color component&gt;]    


#### delta
**Delta**  
  
[https://videoprocessing.ai/vqmt/metrics/#delta](https://videoprocessing.ai/vqmt/metrics/#delta/)    
* _Color components:_ Y, U, V, R, G, B, LUV-L    
* _Type:_ reference metric    
* _Usage:_ `-metr delta` [over &lt;color component&gt;]    


#### msad
**MSAD**  
  
[https://videoprocessing.ai/vqmt/metrics/#msad](https://videoprocessing.ai/vqmt/metrics/#msad/)    
* _Color components:_ Y, U, V, R, G, B, LUV-L    
* _Type:_ reference metric    
* _Usage:_ `-metr msad` [over &lt;color component&gt;]    


#### mse
**MSE**  
  
[https://videoprocessing.ai/vqmt/metrics/#mse](https://videoprocessing.ai/vqmt/metrics/#mse/)    
* _Color components:_ Y, U, V, R, G, B, LUV-L    
* _Type:_ reference metric    
* _Usage:_ `-metr mse` [over &lt;color component&gt;]    


#### time-shift
**Time shift**  
  
[https://videoprocessing.ai/vqmt/metrics/#shift](https://videoprocessing.ai/vqmt/metrics/#shift/)    
* _Color components:_ Y    
* _Type:_ reference metric    
* _Usage:_ `-metr time-shift` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Max. shift    
  Maximum shift, that can be detected. Note: large values leads big memory consumption    
  _Default value:_ `5`    
  _Usage:_ `-set "max-shift=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 0..25    
* Direction    
  Detect only positive shifts (frame dups), negatives (frame drops) or both    
  _Default value:_ `both`    
  _Usage:_ `-set "direction=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `positive`    
  * `negative`    
  * `both`    
* Destination metric    
  This metric will be used to measure similarity between frames    
  _Default value:_ `psnr`    
  _Usage:_ `-set "metric=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `psnr`    
  * `ssim`    
* Show metric values    
  Metric will output now only shift, but destination metric values    
  _Default value:_ `false`    
  _Usage:_ `-set "show-metric=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `true`    
  * `false`    
* Threshold    
  We will consider shift only if metric for neighbour frame better than this thresold multiplied to metric for similar frame    
  _Default value:_ `0.99500000476837158`    
  _Usage:_ `-set "threshold=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any floating point number    
* Smoothing    
  Will smooth metric values over time. If equal n, than smoothing will be in the interval frame-n..frame+n    
  _Default value:_ `1`    
  _Usage:_ `-set "smoothing=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 0..25    


#### si
**SI / TI**  
  
[https://videoprocessing.ai/vqmt/metrics/#si](https://videoprocessing.ai/vqmt/metrics/#si/)    
* _Color components:_ Y    
* _Type:_ no-reference metric    
* _Usage:_ `-metr si` [over &lt;color component&gt;] `-dev CPU`    


#### ti
**SI / TI**  
  
[https://videoprocessing.ai/vqmt/metrics/#ti](https://videoprocessing.ai/vqmt/metrics/#ti/)    
* _Color components:_ Y    
* _Type:_ no-reference metric    
* _Usage:_ `-metr ti` [over &lt;color component&gt;] `-dev CPU`    


#### niqe
**NIQE**  
  
[https://videoprocessing.ai/vqmt/metrics/#niqe](https://videoprocessing.ai/vqmt/metrics/#niqe/)    
* _Color components:_ Y    
* _Type:_ no-reference metric    
* _Usage:_ `-metr niqe` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Mean threshold    
  Values of metric greater than this value will be skipped during mean calculation. 0 for disable skipping    
  _Default value:_ `15.000000000000000`    
  _Usage:_ `-set "mean_thresh=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any floating point number    
* Threshold smoothing    
  Values of metric greater than 'Mean threshold' + 'Threshold smoothing' will be skipped, values less than 'Mean threshold' - 'Threshold smoothing' will be assumed with weight 1. Intermediate values will be taken with intermediate weight    
  _Default value:_ `5.0000000000000000`    
  _Usage:_ `-set "mean_thresh_smoothing=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any floating point number    
* Type of normalization    
  * fast - the fastest algorithm, low precision    
    * native - like in native NIQE implementation. Slowest one    
    * precise - the most precise algorithm    
  _Default value:_ `native`    
  _Usage:_ `-set "norm_alg=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `fast`    
  * `native`    
  * `precise`    
* _Usage:_ `-metr niqe` [over &lt;color component&gt;] `-dev OpenCL0`    
  
This metric can be configured using next parameter(s):    
* Mean threshold    
  Values of metric greater than this value will be skipped during mean calculation. 0 for disable skipping    
  _Default value:_ `15.000000000000000`    
  _Usage:_ `-set "mean_thresh=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any floating point number    
* Threshold smoothing    
  Values of metric greater than 'Mean threshold' + 'Threshold smoothing' will be skipped, values less than 'Mean threshold' - 'Threshold smoothing' will be assumed with weight 1. Intermediate values will be taken with intermediate weight    
  _Default value:_ `5.0000000000000000`    
  _Usage:_ `-set "mean_thresh_smoothing=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any floating point number    


#### vmaf
**Netflix VMAF**  
  
* _Color components:_ Y    
* _Type:_ reference metric    
* _Usage:_ `-metr vmaf` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Model preset    
  Choose built-in model or 'custom' for loading model from file. Built-in models:    
    * default - VMAF default behaviour:    
      - VMAF v0.6.1 for running without confidence interval and per-model values    
      - VMAF v0.6.1 4k for previous case if applying 4k model    
      - VMAF v0.6.3 for running with confidence interval or per-model values    
      - VMAF v0.6.2 4k for previous case if applying 4k model (NOTE: no v0.6.3 for 4k)    
    * vmaf_v061 - Netflix model VMAF v0.6.1 (2k or 4k)    
    * vmaf_v061_neg - Netflix model VMAF v0.6.1 (only 2k), no enhancement gain    
    * vmaf_v062 - Netflix model VMAF v0.6.2 (2k or 4k), supports confidence interval    
    * vmaf_v063 - Netflix model VMAF v0.6.3 (only 2k), supports confidence interval    
    * all_models - vmaf_v061..vmaf_v063, vmaf_v061_neg computed sumultaneously    
    * basic_features - view only basic features from VMAF. Model will not be applied    
    * standard_features - features that is used in VMAF v0.6.1 and VMAF score (2k or 4k)    
    * all_features - view all features from VMAF. Model will not be applied    
    * all_features_with_neg - view all features from VMAF and no enhancement gain features. Model will not be applied    
    * all - all feature and next models:    
      - VMAF v0.6.1 (2k or 4k)    
      - VMAF v0.6.1 no enhancement gain (neg, 2k only)    
      - VMAF v0.6.2 (2k or 4k)    
      - VMAF v0.6.3    
  _Default value:_ `default`    
  _Usage:_ `-set "model_preset=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `vmaf_v061`    
  * `vmaf_v061_neg`    
  * `vmaf_v062`    
  * `vmaf_v063`    
  * `vmaf_v060`    
  * `all_models`    
  * `basic_features`    
  * `standard_features`    
  * `standard_features_neg`    
  * `all_features`    
  * `all_features_with_neg`    
  * `all`    
  * `custom`    
* Custom model (*.pkl or JSON file)    
  you can specify path to *.pkl or JSON file here (or multiple ;-separated *.pkl or JSON files). Model file should be placed near PKL.    
    NOTE: this only means if preset is set to 'custom'    
  _Default value:_ ``    
  _Usage:_ `-set "custom_model_files=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any string    
* 4k    
  selection 4k model policy:    
    * auto - select 4k if exists suitable model and input video is 4k    
    * forced_2k - always 2k model    
    * forced_4k - 4k if exsists: VMAF v0.6.1-2    
    NOTE: this param does not affects custom model    
  _Default value:_ `auto`    
  _Usage:_ `-set "4k=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `auto`    
  * `forced_2k`    
  * `forced_4k`    
* Confidence interval    
  turn on additional VMAF features: 95%-confidence interval output and other statistical information    
  _Default value:_ `false`    
  _Usage:_ `-set "confidence_interval=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `true`    
  * `false`    
* Confidence interval size    
  the length of confidence interval if turned on, percent    
  _Default value:_ `95.000000000000000`    
  _Usage:_ `-set "ci_size=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any floating point number    
* Per-model values    
  output values for all bootstrap models if confidence interval is on    
  _Default value:_ `false`    
  _Usage:_ `-set "permodel_values=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `true`    
  * `false`    
* Bootstrap type    
  output values for all bootstrap models if confidence interval is on    
  _Default value:_ `common`    
  _Usage:_ `-set "bootstrap_type=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `common`    
  * `residue`    
* Visualize algorithm (if on)    
  if visualization turned on you can select feature to visualize. It's impossible to calculate distribution of real VMAF value, so you can only visualize one of supposed features    
  _Default value:_ `default`    
  _Usage:_ `-set "visualize_alg=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `adm`    
  * `ansnr`    
  * `motion`    
  * `vif`    
  * `adm`    
  * `motion`    
  * `vif`    
* Use phone model    
  turn on postprocessing of metric value that produces more precise results for handheld devices. Select 'both' to see both results with and without postprocessing    
  _Default value:_ `no`    
  _Usage:_ `-set "phone_model=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `no`    
  * `yes`    
  * `both`    
* Disable clipping values    
  turn off clipping value to range set by model (0..100 for example)    
  _Default value:_ `false`    
  _Usage:_ `-set "disable_clip=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `true`    
  * `false`    
* Model internal datatype (integer or float)    
  turn off clipping value to range set by model (0..100 for example)    
  _Default value:_ `float`    
  _Usage:_ `-set "datatype=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `float`    
  * `integer`    
* _Usage:_ `-metr vmaf` [over &lt;color component&gt;] `-dev OpenCL0`    


#### vmaf_legacy
**Netflix VMAF legacy**  
  
* _Color components:_ Y    
* _Type:_ reference metric    
* _Usage:_ `-metr vmaf_legacy` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Model preset    
  Choose built-in model or 'custom' for loading model from file. Built-in models:    
    * default - VMAF default behaviour:    
      - VMAF v0.6.1 for running without confidence interval and per-model values    
      - VMAF v0.6.1 4k for previous case if applying 4k model    
      - VMAF v0.6.3 for running with confidence interval or per-model values    
      - VMAF v0.6.2 4k for previous case if applying 4k model (NOTE: no v0.6.3 for 4k)    
    * vmaf_v061 - Netflix model VMAF v0.6.1 (2k or 4k)    
    * vmaf_v061_neg - Netflix model VMAF v0.6.1 (only 2k), no enhancement gain    
    * vmaf_v062 - Netflix model VMAF v0.6.2 (2k or 4k), supports confidence interval    
    * vmaf_v063 - Netflix model VMAF v0.6.3 (only 2k), supports confidence interval    
    * all_models - vmaf_v061..vmaf_v063, vmaf_v061_neg computed sumultaneously    
    * basic_features - view only basic features from VMAF. Model will not be applied    
    * standard_features - features that is used in VMAF v0.6.1 and VMAF score (2k or 4k)    
    * all_features - view all features from VMAF. Model will not be applied    
    * all_features_with_neg - view all features from VMAF and no enhancement gain features. Model will not be applied    
    * all - all feature and next models:    
      - VMAF v0.6.1 (2k or 4k)    
      - VMAF v0.6.1 no enhancement gain (neg, 2k only)    
      - VMAF v0.6.2 (2k or 4k)    
      - VMAF v0.6.3    
  _Default value:_ `default`    
  _Usage:_ `-set "model_preset=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `vmaf_v061`    
  * `vmaf_v062`    
  * `vmaf_v063`    
  * `vmaf_v060`    
  * `all_models`    
  * `basic_features`    
  * `standard_features`    
  * `all_features`    
  * `all`    
  * `custom`    
* Custom model (*.pkl or JSON file)    
  you can specify path to *.pkl or JSON file here (or multiple ;-separated *.pkl or JSON files). Model file should be placed near PKL.    
    NOTE: this only means if preset is set to 'custom'    
  _Default value:_ ``    
  _Usage:_ `-set "custom_model_files=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any string    
* 4k    
  selection 4k model policy:    
    * auto - select 4k if exists suitable model and input video is 4k    
    * forced_2k - always 2k model    
    * forced_4k - 4k if exsists: VMAF v0.6.1-2    
    NOTE: this param does not affects custom model    
  _Default value:_ `auto`    
  _Usage:_ `-set "4k=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `auto`    
  * `forced_2k`    
  * `forced_4k`    
* Confidence interval    
  turn on additional VMAF features: 95%-confidence interval output and other statistical information    
  _Default value:_ `false`    
  _Usage:_ `-set "confidence_interval=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `true`    
  * `false`    
* Confidence interval size    
  the length of confidence interval if turned on, percent    
  _Default value:_ `95.000000000000000`    
  _Usage:_ `-set "ci_size=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * any floating point number    
* Per-model values    
  output values for all bootstrap models if confidence interval is on    
  _Default value:_ `false`    
  _Usage:_ `-set "permodel_values=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `true`    
  * `false`    
* Bootstrap type    
  output values for all bootstrap models if confidence interval is on    
  _Default value:_ `common`    
  _Usage:_ `-set "bootstrap_type=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `common`    
  * `residue`    
* Visualize algorithm (if on)    
  if visualization turned on you can select feature to visualize. It's impossible to calculate distribution of real VMAF value, so you can only visualize one of supposed features    
  _Default value:_ `default`    
  _Usage:_ `-set "visualize_alg=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `adm`    
  * `ansnr`    
  * `motion`    
  * `vif`    
  * `adm`    
  * `motion`    
  * `vif`    
* Use phone model    
  turn on postprocessing of metric value that produces more precise results for handheld devices. Select 'both' to see both results with and without postprocessing    
  _Default value:_ `no`    
  _Usage:_ `-set "phone_model=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `no`    
  * `yes`    
  * `both`    
* Disable clipping values    
  turn off clipping value to range set by model (0..100 for example)    
  _Default value:_ `false`    
  _Usage:_ `-set "disable_clip=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `true`    
  * `false`    
* Model internal datatype (integer or float)    
  turn off clipping value to range set by model (0..100 for example)    
  _Default value:_ `float`    
  _Usage:_ `-set "datatype=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `float`    
  * `integer`    
* _Usage:_ `-metr vmaf_legacy` [over &lt;color component&gt;] `-dev OpenCL0`    


#### hdr-psnr
**PSNR**  
  
[https://videoprocessing.ai/vqmt/metrics/#psnr](https://videoprocessing.ai/vqmt/metrics/#psnr/)    
* _Color components:_ PU-L, PU encoding BT.709 L, PU encoding BT.2020 L, ICtCp BT.2100 PQ ICtCp    
* _Type:_ reference metric    
* _Usage:_ `-metr hdr-psnr` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Peak luminance (nits)    
  PSNR peak luminance value. 0 means display luminance    
  _Default value:_ `0.00000000000000000`    
  _Usage:_ `-set "peak_lum=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 0..10000    


#### hdr-ssim
**HDR SSIM**  
  
[https://videoprocessing.ai/vqmt/metrics/#ssim](https://videoprocessing.ai/vqmt/metrics/#ssim/)    
* _Color components:_ PU-L, PU encoding BT.709 L, PU encoding BT.2020 L    
* _Type:_ reference metric    
* _Usage:_ `-metr hdr-ssim` [over &lt;color component&gt;] `-dev CPU`    
  
This metric can be configured using next parameter(s):    
* Combining mode    
  The mode of combining values for components of image:    
    * default - in case of YUV image custom weight for Y component will be used, equal weights for U, V components will be used. In case if other color models equvivalent weights will be used    
    * ffmpeg - use area of component. Weights will depend on subsampling mode of image    
  _Default value:_ `default`    
  _Usage:_ `-set "combining_mode=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `ffmpeg`    
* Y weight    
  If combining mode is default this is weight of value for component Y of YUV. Weights of U, V and other components is supposes to be 1.    
  _Default value:_ `4.0000000000000000`    
  _Usage:_ `-set "y_weight=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * 0.00000000000000000    
  * 999999.00000000000    
* _Usage:_ `-metr hdr-ssim` [over &lt;color component&gt;] `-dev CPU`    
* _Usage:_ `-metr hdr-ssim` [over &lt;color component&gt;] `-dev CPU`    
* _Usage:_ `-metr hdr-ssim` [over &lt;color component&gt;] `-dev OpenCL0`    


#### hdr-msssim
**HDR MS-SSIM**  
  
[https://videoprocessing.ai/vqmt/metrics/#msssim](https://videoprocessing.ai/vqmt/metrics/#msssim/)    
* _Color components:_ PU-L, PU encoding BT.709 L, PU encoding BT.2020 L    
* _Type:_ reference metric    
* _Usage:_ `-metr hdr-msssim` [over &lt;color component&gt;] `-dev CPU`    
  
This metric can be configured using next parameter(s):    
* Combining mode    
  The mode of combining values for components of image:    
    * default - in case of YUV image custom weight for Y component will be used, equal weights for U, V components will be used. In case if other color models equvivalent weights will be used    
    * ffmpeg - use area of component. Weights will depend on subsampling mode of image    
  _Default value:_ `default`    
  _Usage:_ `-set "combining_mode=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `ffmpeg`    
* Y weight    
  If combining mode is default this is weight of value for component Y of YUV. Weights of U, V and other components is supposes to be 1.    
  _Default value:_ `4.0000000000000000`    
  _Usage:_ `-set "y_weight=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * 0.00000000000000000    
  * 999999.00000000000    
[https://videoprocessing.ai/vqmt/metrics/#ssim](https://videoprocessing.ai/vqmt/metrics/#ssim/)    
* _Usage:_ `-metr hdr-msssim` [over &lt;color component&gt;] `-dev CPU`    
[https://videoprocessing.ai/vqmt/metrics/#msssim](https://videoprocessing.ai/vqmt/metrics/#msssim/)    
* _Usage:_ `-metr hdr-msssim` [over &lt;color component&gt;] `-dev CPU`    
* _Usage:_ `-metr hdr-msssim` [over &lt;color component&gt;] `-dev OpenCL0`    
  
This metric can be configured using next parameter(s):    
* Combining mode    
  The mode of combining values for components of image:    
    * default - in case of YUV image custom weight for Y component will be used, equal weights for U, V components will be used. In case if other color models equvivalent weights will be used    
    * ffmpeg - use area of component. Weights will depend on subsampling mode of image    
  _Default value:_ `default`    
  _Usage:_ `-set "combining_mode=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * `default`    
  * `ffmpeg`    
* Y weight    
  If combining mode is default this is weight of value for component Y of YUV. Weights of U, V and other components is supposes to be 1.    
  _Default value:_ `4.0000000000000000`    
  _Usage:_ `-set "y_weight=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * 0.00000000000000000    
  * 999999.00000000000    


#### hdr-vqm
**HDRVQM**  
  
[https://sites.google.com/site/narwariam/home/research/hdr-vqm](https://sites.google.com/site/narwariam/home/research/hdr-vqm/)    
* _Color components:_ PU-L, PU encoding BT.709 L, PU encoding BT.2020 L    
* _Type:_ reference metric    
* _Usage:_ `-metr hdr-vqm` [over &lt;color component&gt;]    
  
This metric can be configured using next parameter(s):    
* Fixation frames    
  Number of frame for calculation of spatio-temporal tubes. 0 - auto (0.6 seconds, based on fps of first video)    
  _Default value:_ `0`    
  _Usage:_ `-set "fixation_frames=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 0..50    
* FFT cols    
  Video will be scaled to this value (bicubic). 0 - auto (clothest to video size)    
  _Default value:_ `1024`    
  _Usage:_ `-set "fft_cols=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 64..32768    
* FFT rows    
  Video will be scaled to this value (bicubic). 0 - auto (clothest to video size)    
  _Default value:_ `512`    
  _Usage:_ `-set "fft_rows=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 64..32768    
* Pooling Percentage    
  Pooling Percentage for long-term pooling    
  _Default value:_ `0.30000001192092896`    
  _Usage:_ `-set "pooling_precent=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 0.10000000000000001..1.0000000000000000    
* Dispaly: cols    
  Columns of the target display    
  _Default value:_ `1920.0000000000000`    
  _Usage:_ `-set "display_cols=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 500..10000    
* Dispaly: rows    
  Rows of the target display    
  _Default value:_ `1080.0000000000000`    
  _Usage:_ `-set "display_rows=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 500..10000    
* Dispaly: area    
  Area of the target display    
  _Default value:_ `6100.0000000000000`    
  _Usage:_ `-set "display_area=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 500.00000000000000..100000.00000000000    
* Dispaly: distance    
  Viewer's dispaly distance, cm    
  _Default value:_ `178.00000000000000`    
  _Usage:_ `-set "display_distance=`&lt;value&gt;`"`, where &lt;value&gt; can be:    
  * value in range 10.000000000000000..100.00000000000000    


#### delta-ictcp
**Delta**  
  
[https://videoprocessing.ai/vqmt/metrics/#delta](https://videoprocessing.ai/vqmt/metrics/#delta/)    
* _Color components:_ ICtCp BT.2100 PQ ICtCp    
* _Type:_ reference metric    
* _Usage:_ `-metr delta-ictcp` [over &lt;color component&gt;]    






This page is automatically generated by 14.1 r12839 on 2022-06-24. In case of any question or suggestion, please mail us: [video-measure@compression.ru](video-measure@compression.ru)
