<!DOCTYPE html>
<html lang="en">
  <head prefix="og: https://ogp.me/ns#">
    <link href="/assets/favicon/favicon.ico" rel="shortcut icon">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <title>MSU Video Frame Interpolation Benchmark Methodology</title>
    <meta property="og:title" content="MSU Video Frame Interpolation Benchmark Methodology">
    <meta property="og:image" content="http://localhost:4000/assets/img/logo.svg">
    <meta name="description" content="Evaluation Methodology of Video Frame Interpolation Benchmark">
    <meta property="og:description" content="Evaluation Methodology of Video Frame Interpolation Benchmark">
    <meta property="og:url" content="
http://localhost:4000/benchmarks/video-frame-interpolation-methodology.html
">
    <meta property="og:type" content="website">
    <link href="/assets/css/common.css" rel="stylesheet" type="text/css">
    <script src="/assets/js/interface.js"></script>
    <link rel="stylesheet" type="text/css" href="/assets/css/nav_arrow.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>
  <body>
    <ul class="navbar">
      <li class="navbar-header">
        <a href="/" class="header">
          <img alt="Main page" class="logo" src="/assets/img/logo.svg">
          <h1>Video processing, compression<br>
            and quality research group
            <div>Based in MSU Graphics & Media Laboratory</div>
          </h1>
        </a>
        <a class="menu-toggle-button">
          <div class="icon"></div>
        </a>
      </li>
      <li>
        <a href="/benchmarks/">Benchmarks <img class="dropdown-icon" src="/assets/icons/dropdown.svg"></a>
        <ul class="dropmenu">
          <li><a href="/benchmarks/deblurring.html">MSU Video Deblurring Benchmark 2022</a></li>
          <li><a href="/benchmarks/video-frame-interpolation.html">MSU Video Frame Interpolation Benchmark 2022</a></li>
          <li><a href="/benchmarks/video-upscalers.html">MSU Video Upscalers Benchmark 2022</a></li>
          <li><a href="/benchmarks/inverse-tone-mapping.html">MSU HDR Video Reconstruction Benchmark 2022</a></li>
          <li><a href="/benchmarks/super-resolution-for-video-compression.html">MSU Super-Resolution for Video Compression Benchmark 2022</a></li>
          <li><a href="/benchmarks/no-reference-video-quality-metrics.html">MSU No-Reference Video Quality Metrics Benchmark 2022</a></li>
          <li><a href="/benchmarks/full-reference-video-quality-metrics.html">MSU Full-Reference Video Quality Metrics Benchmark 2022</a></li>
          <li><a href="/benchmarks/aligners.html">MSU Video Alignment and Retrieval Benchmark</a></li>
          <li><a href="/benchmarks/mobile-video-codec-benchmark.html">MSU Mobile Video Codecs Benchmark 2021</a></li>
          <li><a href="/benchmarks/video-super-resolution.html">MSU Video Super-Resolution Benchmark</a></li>
          <li><a href="/benchmarks/shot-boundary-detection.html">MSU Shot Boundary Detection Benchmark 2020</a></li>
          <li><a href="/benchmarks/deinterlacer.html">MSU Deinterlacer Benchmark</a></li>
          <li><a href="https://videomatting.com/" target="_blank">The VideoMatting Project</a></li>
          <li><a href="https://videocompletion.org/" target="_blank">Video Completion</a></li>
        </ul>
      </li>
      <li>
        <a href="/projects/">Projects <img class="dropdown-icon" src="/assets/icons/dropdown.svg"></a>
        <ul class="dropmenu">
          <li><a href="/codecs/">Codecs Comparisons & Optimization</a></li>
          <li><a href="/vqmt/">VQMT</a></li>
          <li><a href="/stereo_quality/">Video Quality Measurement Tool 3D</a></li>
          <li><a href="/datasets/">MSU Datasets Collection</a></li>
          <li><a href="/metrics/">Metrics Research</a></li>
          <li><a href="/video_filters/">Video Filters</a></li>
          <li><a href="/other/">Other Projects</a></li>
        </ul>
      </li>
      <li><a href="/publications/">Publications</a></li>
      <li><a href="/about/">About Us</a></li>
      <li><a href="/contacts/">Contacts</a></li>
    </ul>
    <div class="content">
      <link href="/assets/css/post.css" rel="stylesheet" type="text/css">
      <div class="tiles-width nav-current">
        <a href="/index.html">Main page</a> &mdash;
        <a href="/benchmarks/">MSU Benchmark Collection</a>
      </div>
      <div class="tiles-width markdown article">
        <link rel="stylesheet" href="/assets/css/benchmarks/style.css" />
        <script src="https://code.highcharts.com/highcharts.js"></script>
        <script src="https://code.highcharts.com/modules/exporting.js"></script>
        <script src="https://code.highcharts.com/modules/export-data.js"></script>
        <script src="https://code.highcharts.com/modules/accessibility.js"></script>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script src="https://code.highcharts.com/highcharts-more.js"></script>
        <link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.10.22/css/jquery.dataTables.css" />
        <script type="text/javascript" charset="utf8" src="https://cdn.datatables.net/1.10.22/js/jquery.dataTables.js"></script>
        <link rel="stylesheet" href="/assets/css/benchmarks/upscalers/style.css" />
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
        <h1 id="evaluation-methodology-of-msu-video-frame-interpolation-benchmark-2022">Evaluation Methodology of MSU Video Frame Interpolation Benchmark 2022</h1>
        <div id="buttons"></div>
        <script>
          __set_menu_buttons([
          ['Home', '/benchmarks/video-frame-interpolation.html'],
          ['Participants','video-frame-interpolation-participants.html'],
              ['Dataset', '/benchmarks/video-frame-interpolation-dataset.html'],
          ['Evaluation methodology', '/benchmarks/video-frame-interpolation-methodology.html'],
              ['How to participate', '/benchmarks/video-frame-interpolation.html#participate'],
              ['Contact us', '/benchmarks/video-frame-interpolation.html#contacts']
          ], 'Evaluation methodology')
        </script>
        <div class="current_content">
          <h2 id="problem-definition">Problem definition</h2>
          <p>Video Frame Interpolation (VFI) algorithms synthesize non-existent images between adjacent frames, with the aim of providing a smooth and consistent visual experience.<br />
            Our benchmark will rank these algorithms and determine which is the best by means of interpolation quality.</p>
          <h2 id="dataset">Dataset</h2>
          <p>We present <strong>a new dataset</strong> for this comparison. This was done to ensure that neural network methods do not benefit from training on data that could get into our test sample.<br />
            Details about Dataset characteristics and processing you can find in <a href="/benchmarks/video-frame-interpolation-dataset.html">Dataset tab</a>.</p>
          <h2 id="metrics">Metrics</h2>
          <h4 id="psnr">PSNR</h4>
          <p>PSNR – commonly used metric based on pixels’ similarity. For metric calculation, we use the implementation from MSU VQMT<sup><a href="#references">[1]</a></sup>. A higher metric value indicates better quality.</p>
          <h4 id="ssim">SSIM</h4>
          <p>SSIM – another commonly used metric based on structure similarity. For metric calculation, we use the implementation from MSU VQMT<sup><a href="#references">[1]</a></sup>. A higher metric value indicates better quality.</p>
          <h3 id="ms-ssim">MS-SSIM</h3>
          <p>Multiscale SSIM (MS-SSIM) is conducted over multiple scales through a process of multiple stages of sub-sampling. Implementation from Pytorch MS-SSIM<sup><a href="#references">[2]</a></sup>. A higher metric value indicates better quality.</p>
          <h3 id="vmaf">VMAF</h3>
          <p>VMAF is a perceptual video quality assessment algorithm developed by Netflix. In our benchmark, we calculate VMAF on the Y component in YUV colorspace. For metric calculation, we use MSU VQMT<sup><a href="#references">[1]</a></sup>.</p>
          <h3 id="lpips">LPIPS</h3>
          <p>LPIPS (Learned Perceptual Image Patch Similarity) evaluates the distance between image patches. Higher means further/more different. Lower means more similar. To calculate LPIPS we use Perceptual Similarity Metric implementation proposed in The Unreasonable Effectiveness of Deep Features as a Perceptual Metric<sup><a href="#references">[3]</a></sup>.</p>
          <h2 id="computational-complexity">Computational complexity</h2>
          <p>The tests were performed in Google Colab. Main characteristics:</p>
          <ul>
            <li>GPU: <strong>NVIDIA K80</strong></li>
            <li>reading and writing images are not taken into account</li>
            <li><strong>1920×1080</strong> resolution</li>
            <li>interpolation of one frame between the same pair of adjacent frames</li>
            <li>result is <strong>3rd minimum from 100 runs</strong></li>
          </ul>
          <h2 id="subjective-comparison">Subjective comparison</h2>
          <p>For the subjective comparison we slow down outputs from algorithms in 4 times. For the participants are shown 2 seconds length videos:</p>
          <ul>
            <li>30 fps for gaming samples</li>
            <li>60 fps for others</li>
          </ul>
          <p>Each one of 413 participants has seen 32 video pairs and had to choose which one of them looks more smooth (option “indistinguishable” is also available). There were 2 verification questions to protect against random answers and bots. We used these valid answers to predict the ranking using the Bradley-Terry model.</p>
          <h3 id="references">References</h3>
          <ol>
            <li><a href="http://compression.ru/video/quality_measure/video_measurement_tool.html">http://compression.ru/video/quality_measure/video_measurement_tool.html</a></li>
            <li><a href="https://github.com/VainF/pytorch-msssim">Pytorch MS-SSIM</a></li>
            <li><a href="https://richzhang.github.io/PerceptualSimilarity/">https://richzhang.github.io/PerceptualSimilarity/</a></li>
            <!-- <li>R. Zhang, P. Isola, A. A. Efros, E. Shechtman, O. Wang, "The unreasonable effectiveness of deep features as a perceptual metric," in Proceedings of the IEEE conference on computer vision and pattern recognition, 2020, pp.586-595.</li> 
    <li><a href="https://videoprocessing.ai/benchmarks/video-super-resolution.html">https://videoprocessing.ai/benchmarks/video-super-resolution.html</a></li>
    <li><a href="https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de">https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de</a></li>
    <li><a href="https://en.wikipedia.org/wiki/Canny_edge_detector">https://en.wikipedia.org/wiki/Canny_edge_detector</a></li>
    <li>A. V. Zvezdakova, D. L. Kulikov, S. V. Zvezdakov, D. S. Vatolin, "BSQ-rate: a new approach for video-codec performance comparison and drawbacks of current solutions," in Programming and computer software, vol. 46, 2020, pp.183-194.</li>
    <li><a href="https://videoprocessing.ai/benchmarks/video-super-resolution-methodology.html">https://videoprocessing.ai/benchmarks/video-super-resolution-methodology.html</a></li>
    <li><a href="http://app.subjectify.us/">http://app.subjectify.us/</a></li>
    <li><a href="https://github.com/fraunhoferhhi/vvenc">https://github.com/fraunhoferhhi/vvenc</a></li>
    <li><a href="https://github.com/uavs3/uavs3e">https://github.com/uavs3/uavs3e</a></li>
    <li>A. Antsiferova, A. Yakovenko, N. Safonov, D. Kulikov, A. Gushin, D.Vatolin, "Objective video quality metrics application to video codecs comparisons: choosing the best for subjective quality estimation," in arXiv preprint arXiv:2107.10220, 2021</li>
    <li><a href="https://github.com/alexanderkroner/saliency">https://github.com/alexanderkroner/saliency</a></li>
    <li>A. Kroner, M. Senden, K. Driessens, and R. Goebel, "Contextual encoder-decoder network for visual saliency prediction," in Neural Networks, 129, pp. 261-270, 2020.</li> -->
          </ol>
        </div>
      </div>
      <div class="tiles-width meta">
        <div class="share">
          <link href="/assets/css/sharing-buttons.css" rel="stylesheet" type="text/css">
          <!-- Sharingbutton Twitter -->
          <a class="resp-sharing-button__link"
   href="https://twitter.com/intent/tweet/?text=MSU Video Frame Interpolation Benchmark Methodology&amp;url=
http://localhost:4000/benchmarks/video-frame-interpolation-methodology.html
"
   target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton Telegram -->
          <a aria-label=""
   class="resp-sharing-button__link"
   href="https://telegram.me/share/url?text=MSU Video Frame Interpolation Benchmark Methodology&amp;url=
http://localhost:4000/benchmarks/video-frame-interpolation-methodology.html
" rel="noopener" target="_blank">
            <div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M.707 8.475C.275 8.64 0 9.508 0 9.508s.284.867.718 1.03l5.09 1.897 1.986 6.38a1.102 1.102 0 0 0 1.75.527l2.96-2.41a.405.405 0 0 1 .494-.013l5.34 3.87a1.1 1.1 0 0 0 1.046.135 1.1 1.1 0 0 0 .682-.803l3.91-18.795A1.102 1.102 0 0 0 22.5.075L.706 8.475z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton Facebook -->
          <a aria-label=""
   class="resp-sharing-button__link"
   href="https://facebook.com/sharer/sharer.php?u=
http://localhost:4000/benchmarks/video-frame-interpolation-methodology.html
" rel="noopener"
   target="_blank">
            <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M18.77 7.46H14.5v-1.9c0-.9.6-1.1 1-1.1h3V.5h-4.33C10.24.5 9.5 3.44 9.5 5.32v2.15h-3v4h3v12h5v-12h3.85l.42-4z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton E-Mail -->
          <a class="resp-sharing-button__link"
   href="mailto:?subject=MSU Video Frame Interpolation Benchmark Methodology&amp;body=
http://localhost:4000/benchmarks/video-frame-interpolation-methodology.html
" target="_self" rel="noopener"
   aria-label="">
            <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M22 4H2C.9 4 0 4.9 0 6v12c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zM7.25 14.43l-3.5 2c-.08.05-.17.07-.25.07-.17 0-.34-.1-.43-.25-.14-.24-.06-.55.18-.68l3.5-2c.24-.14.55-.06.68.18.14.24.06.55-.18.68zm4.75.07c-.1 0-.2-.03-.27-.08l-8.5-5.5c-.23-.15-.3-.46-.15-.7.15-.22.46-.3.7-.14L12 13.4l8.23-5.32c.23-.15.54-.08.7.15.14.23.07.54-.16.7l-8.5 5.5c-.08.04-.17.07-.27.07zm8.93 1.75c-.1.16-.26.25-.43.25-.08 0-.17-.02-.25-.07l-3.5-2c-.24-.13-.32-.44-.18-.68s.44-.32.68-.18l3.5 2c.24.13.32.44.18.68z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton LinkedIn -->
          <a class="resp-sharing-button__link"
   href="https://www.linkedin.com/shareArticle?mini=true&amp;url=
http://localhost:4000/benchmarks/video-frame-interpolation-methodology.html
&amp;title=MSU Video Frame Interpolation Benchmark Methodology&amp;summary=MSU Video Frame Interpolation Benchmark Methodology&amp;source=
http://localhost:4000/benchmarks/video-frame-interpolation-methodology.html
"
   target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"/>
              </svg>
            </div>
          </a>
        </div>
        <span class="date">04 Oct 2022</span>
      </div>
      <div class="tiles-width separator"></div>
      <div class="tiles-width see-also-title">
        See Also
      </div>
      <div class="tiles wide">
        <a class="tile" href="/benchmarks/deblurring.html">
          <div class="image" style="background-image: url(/assets/img/benchmarks/deblurring/preview.png)"></div>
          <div class="title">MSU Video Deblurring Benchmark 2022</div>
          <div class="text">Learn about the best video deblurring methods and choose the best model</div>
        </a>
        <a class="tile" href="/benchmarks/video-frame-interpolation.html">
          <div class="image" style="background-image: url(/assets/img/benchmarks/vfi/main.webp)"></div>
          <div class="title">MSU Video Frame Interpolation Benchmark 2022</div>
          <div class="text">Discover the best algorithm to make high-quality and smooth slow motion videos</div>
        </a>
      </div>
      <div class="tiles-width separator"></div>
      <div class="tiles-width markdown site-structure">
        <span class="title">Site structure</span>
        <ul>
          <li>
            <a href="/benchmarks/">MSU Benchmark Collection</a>
            <ul>
              <li><a href="/benchmarks/deblurring.html">MSU Video Deblurring Benchmark 2022</a></li>
              <li><a href="/benchmarks/video-frame-interpolation.html">MSU Video Frame Interpolation Benchmark 2022</a></li>
              <li><a href="/benchmarks/video-upscalers.html">MSU Video Upscalers Benchmark 2022</a></li>
              <li><a href="/benchmarks/inverse-tone-mapping.html">MSU HDR Video Reconstruction Benchmark 2022</a></li>
              <li><a href="/benchmarks/super-resolution-for-video-compression.html">MSU Super-Resolution for Video Compression Benchmark 2022</a></li>
              <li><a href="/benchmarks/no-reference-video-quality-metrics.html">MSU No-Reference Video Quality Metrics Benchmark 2022</a></li>
              <li><a href="/benchmarks/full-reference-video-quality-metrics.html">MSU Full-Reference Video Quality Metrics Benchmark 2022</a></li>
              <li><a href="/benchmarks/aligners.html">MSU Video Alignment and Retrieval Benchmark</a></li>
              <li><a href="/benchmarks/mobile-video-codec-benchmark.html">MSU Mobile Video Codecs Benchmark 2021</a></li>
              <li><a href="/benchmarks/video-super-resolution.html">MSU Video Super-Resolution Benchmark</a></li>
              <li><a href="/benchmarks/shot-boundary-detection.html">MSU Shot Boundary Detection Benchmark 2020</a></li>
              <li><a href="/benchmarks/deinterlacer.html">MSU Deinterlacer Benchmark</a></li>
              <li><a href="https://videomatting.com/" target="_blank">The VideoMatting Project</a></li>
              <li><a href="https://videocompletion.org/" target="_blank">Video Completion</a></li>
            </ul>
          </li>
          <li>
            <a href="/codecs/">Codecs Comparisons & Optimization</a>
            <ul>
              <li><a href="/codecs/avc/">AVC Codecs Comparison</a></li>
              <li><a href="/codecs/hevc/">HEVC Codecs Comparison</a></li>
              <li><a href="/codecs/image/">Image Codecs Comparison</a></li>
              <li><a href="/codecs/lossless/">Lossless Codecs Comparison</a></li>
              <li><a href="/codecs/optimization/">Codecs Optimization and Tuning</a></li>
              <li><a href="/codecs/reports/">All Codecs Comparison Reports</a></li>
            </ul>
          </li>
          <li>
            <a href="/vqmt/">VQMT</a>
            <ul>
              <li><a href="/vqmt/plugins/">VQMT Plugins</a></li>
            </ul>
          </li>
          <li>
            <a href="/stereo_quality/">Video Quality Measurement Tool 3D</a>
            <ul>
              <li><a href="/stereo_quality/correction/">Stereo Artifacts Correction</a></li>
              <li><a href="/stereo_quality/metrics/">Stereo Quality Metrics</a></li>
              <li><a href="/stereo_quality/reports/">All Stereo Quality Reports</a></li>
            </ul>
          </li>
          <li>
            <a href="/datasets/">MSU Datasets Collection</a>
            <ul>
            </ul>
          </li>
          <li>
            <a href="/metrics/">Metrics Research</a>
            <ul>
            </ul>
          </li>
          <li>
            <a href="/video_filters/">Video Filters</a>
            <ul>
              <li><a href="/video_filters/image/">Image Processing Filters</a></li>
              <li><a href="/video_filters/public/">Free Filters</a></li>
              <li><a href="/video_filters/virtualdub/">VirtualDub Filters</a></li>
            </ul>
          </li>
          <li>
            <a href="/other/">Other Projects</a>
            <ul>
            </ul>
          </li>
        </ul>
      </div>
    </div>
    <div class="footer">
      <div class="footer-column copyright">
        <img alt="MSU Graphics & Multimedia Lab Video Group" class="logo" src="/assets/img/logo.svg">
        <div class="text">
          MSU Graphics & Media Lab Video Group
          <br>
          2019&ndash;2022
        </div>
      </div>
      <div class="footer-column">
        <ul>
          <li><a href="/codecs/">Codecs Comparisons & Optimization</a></li>
          <li><a href="/vqmt/">VQMT</a></li>
          <li><a href="/stereo_quality/">Video Quality Measurement Tool 3D</a></li>
          <li><a href="/datasets/">MSU Datasets Collection</a></li>
          <li><a href="/metrics/">Metrics Research</a></li>
          <li><a href="/video_filters/">Video Filters</a></li>
          <li><a href="/other/">Other Projects</a></li>
        </ul>
      </div>
      <div class="footer-column">
        <ul>
          <li><a href="/about/">About Us</a></li>
          <li><a href="/benchmarks/">Benchmarks</a></li>
          <li><a href="/projects/">Projects</a></li>
          <li><a href="/publications/">Publications</a></li>
          <li><a href="/contacts/">Contacts</a></li>
        </ul>
      </div>
    </div>
  </body>
</html>