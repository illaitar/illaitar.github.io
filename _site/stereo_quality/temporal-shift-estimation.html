<!DOCTYPE html>
<html lang="en">
  <head prefix="og: https://ogp.me/ns#">
    <link href="/assets/favicon/favicon.ico" rel="shortcut icon">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <title>Temporal shift estimation for stereoscopic videos</title>
    <meta property="og:title" content="Temporal shift estimation for stereoscopic videos">
    <meta property="og:image" content="http://localhost:4000/assets/img/vqmt3d/temporal-shift-estimation/preview.gif">
    <meta name="description" content="How to take into account geometric distortions in the estimation of the temporal shift?">
    <meta property="og:description" content="How to take into account geometric distortions in the estimation of the temporal shift?">
    <meta property="og:url" content="
http://localhost:4000/stereo_quality/temporal-shift-estimation.html
">
    <meta property="og:type" content="website">
    <link href="/assets/css/common.css" rel="stylesheet" type="text/css">
    <script src="/assets/js/interface.js"></script>
    <link rel="stylesheet" type="text/css" href="/assets/css/nav_arrow.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>
  <body>
    <ul class="navbar">
      <li class="navbar-header">
        <a href="/" class="header">
          <img alt="Main page" class="logo" src="/assets/img/logo.svg">
          <h1>Video processing, compression<br>
            and quality research group
            <div>Based in MSU Graphics & Media Laboratory</div>
          </h1>
        </a>
        <a class="menu-toggle-button">
          <div class="icon"></div>
        </a>
      </li>
      <li>
        <a href="/benchmarks/">Benchmarks <img class="dropdown-icon" src="/assets/icons/dropdown.svg"></a>
        <ul class="dropmenu">
          <li><a href="/benchmarks/deblurring.html">MSU Video Deblurring Benchmark 2022</a></li>
          <li><a href="/benchmarks/video-frame-interpolation.html">MSU Video Frame Interpolation Benchmark 2022</a></li>
          <li><a href="/benchmarks/video-upscalers.html">MSU Video Upscalers Benchmark 2022</a></li>
          <li><a href="/benchmarks/inverse-tone-mapping.html">MSU HDR Video Reconstruction Benchmark 2022</a></li>
          <li><a href="/benchmarks/super-resolution-for-video-compression.html">MSU Super-Resolution for Video Compression Benchmark 2022</a></li>
          <li><a href="/benchmarks/no-reference-video-quality-metrics.html">MSU No-Reference Video Quality Metrics Benchmark 2022</a></li>
          <li><a href="/benchmarks/full-reference-video-quality-metrics.html">MSU Full-Reference Video Quality Metrics Benchmark 2022</a></li>
          <li><a href="/benchmarks/aligners.html">MSU Video Alignment and Retrieval Benchmark</a></li>
          <li><a href="/benchmarks/mobile-video-codec-benchmark.html">MSU Mobile Video Codecs Benchmark 2021</a></li>
          <li><a href="/benchmarks/video-super-resolution.html">MSU Video Super-Resolution Benchmark</a></li>
          <li><a href="/benchmarks/shot-boundary-detection.html">MSU Shot Boundary Detection Benchmark 2020</a></li>
          <li><a href="/benchmarks/deinterlacer.html">MSU Deinterlacer Benchmark</a></li>
          <li><a href="https://videomatting.com/" target="_blank">The VideoMatting Project</a></li>
          <li><a href="https://videocompletion.org/" target="_blank">Video Completion</a></li>
        </ul>
      </li>
      <li>
        <a href="/projects/">Projects <img class="dropdown-icon" src="/assets/icons/dropdown.svg"></a>
        <ul class="dropmenu">
          <li><a href="/codecs/">Codecs Comparisons & Optimization</a></li>
          <li><a href="/vqmt/">VQMT</a></li>
          <li><a href="/stereo_quality/">Video Quality Measurement Tool 3D</a></li>
          <li><a href="/datasets/">MSU Datasets Collection</a></li>
          <li><a href="/metrics/">Metrics Research</a></li>
          <li><a href="/video_filters/">Video Filters</a></li>
          <li><a href="/other/">Other Projects</a></li>
        </ul>
      </li>
      <li><a href="/publications/">Publications</a></li>
      <li><a href="/about/">About Us</a></li>
      <li><a href="/contacts/">Contacts</a></li>
    </ul>
    <div class="content">
      <link href="/assets/css/post.css" rel="stylesheet" type="text/css">
      <div class="tiles-width nav-current">
        <a href="/index.html">Main page</a> &mdash;
        <a href="/stereo_quality/">Video Quality Measurement Tool 3D</a>
        &mdash;
        <a href="/stereo_quality/metrics/">Stereo Quality Metrics</a>
      </div>
      <div class="tiles-width markdown article">
        <h1 id="temporal-shift-estimation-for-stereoscopic-videos">Temporal shift estimation for stereoscopic videos</h1>
        <ul>
          <li>Author: Aleksandr Ploshkin</li>
          <li>Supervisor: dr. Dmitriy Vatolin</li>
        </ul>
        <h2 id="introduction">Introduction</h2>
        <p>Video synchronization is a fundamental computer-vision task necessary for a wide range of applications. A 3D video involves two streams, which show the scene from different angles simultaneously. It was demonstrated that desynchronization between streams causes severe discomfort for people watching the stereo video.</p>
        <p>We propose a temporal shift (time difference) estimation method. In this method we assume that the temporal shift and geometric distortion between the two streams are constant throughout each scene. The result of the algorithm is a shift value measured in fractions of frame steps (inverted FPS).</p>
        <p><b>Example of a detected shot with temporal shift<br />
            Drive Angry</b></p>
        <div align="left">
          <p><img src="/assets/img/vqmt3d/temporal-shift-estimation/drive_angry.gif" /></p>
        </div>
        <p>We approached the task as a regression problem by constructing an equation that describes the spatio-temporal dependency using the motion disparity and stereo parallax vectors.</p>
        <p>The proposed algorithm consists of the following two main stages:</p>
        <ol>
          <li>Calculate the stereo parallax and motion vectors using a block-based matching for each stereo frame;</li>
          <li>Estimate model parameters from motion vectors with high confidence using the RANSAC algorithm.</li>
        </ol>
        <p>Stereoscopic video can employ horizontal disparity by design in order to achieve the stereo effect, but vertical disparity is always the result of spatio-temporal misalignment. The algorithm uses this assumption to restore a temporal shift value from vectors’ vertical components. The detailed algorithm description is published in <a href="#1">[1]</a>.</p>
        <p><b>A histogram of founded values. The tangent of the slope is the shift value in frames’ fractions</b></p>
        <div align="left">
          <p><img src="/assets/img/vqmt3d/temporal-shift-estimation/histogram.png" /></p>
        </div>
        <h2 id="experiments">Experiments</h2>
        <p>The algorithm has been tested on our synthetically created dataset. The video set contained 396 stereoscopic scenes with frame rate of 30 FPS from only converted stereoscopic movies, as they did not contain temporal shifts. The frames were subsampled to simulate the temporal shift (e.g. taking only even frames for the left view and uneven frames for the right view results in a shift of 0.5 frames). The final dataset consisted of subsampled views, resulting in a relative temporal shift by ±{0.25, 0.5, 1.0, 2.0} frames.</p>
        <p>The comparison of the current algorithm with the previous work shows a significant gain. The error was calculated as the absolute difference between the target and estimated shift values in the frame steps. The evaluation problem was addressed as a classification of whether the error was below a threshold value. In the experiments, the least noticeable value of the time shift was estimated to be 0.10 frames, and it was used as a threshold error value for comparing algorithms.</p>
        <style type="text/css">
          #wrap {
             width:100%;
             margin:0 auto;
          }
          #left_col {
             float:left;
             width:50%;
          }
          #right_col {
             float:right;
             width:50%;
          }
        </style>
        <div id="wrap">
          <div id="left_col">
            <p><img src="/assets/img/vqmt3d/temporal-shift-estimation/error.png" align="left" /></p>
          </div>
          <div id="right_col">
            <p><img src="/assets/img/vqmt3d/temporal-shift-estimation/accuracy.png" align="right" /></p>
          </div>
          <p>
            <div style="text-align: center; clear: both;"><b>The comparison of proposed algorithm with our previous work <a href="#1">[1]</a>.  Left: the relation between the temporal shift accuracy and the estimation error threshold; Right: the exact scores for error threshold value equal to 0.10 frames.</b>
            </div>
          </p>
        </div>
        <p>Additionally, we’ve processed 60 full-length stereoscopic movies and revealed 198 scenes with temporal shift value at least 0.10 frames. Further examples can be found in our VQMT3D reports <a href="/stereo_quality/report8.html">8</a> and <a href="/stereo_quality/report9.html">9</a>.</p>
        <p><b>Histogram of revealed scenes with temporal shift</b></p>
        <div align="left">
          <p><img src="/assets/img/vqmt3d/temporal-shift-estimation/temporal_shift.png" /></p>
        </div>
        <h2 id="results">Results</h2>
        <ul>
          <li>Developed a temporal shift estimation algorithm
            <ul>
              <li>Speed: 0.9 FPS at Intel Core i7-4700HQ CPU</li>
              <li>Accuracy: 0.9798 for 0.1 frames error threshold</li>
            </ul>
          </li>
          <li>Revealed 198 shifted scenes in 60 feature-length stereoscopic movies</li>
        </ul>
        <h2 id="publications">Publications</h2>
        <p><a id="1">1.</a> Ploshkin, A., and Vatolin, D.,<br />
          <b>“Accurate method of temporal-shift estimation for 3D video,”</b> [<a href="https://istina.msu.ru/download/172728093/1iwpfY:OtcJLggCDeUg3b7-O1kM2U3McX8/">pdf</a>]<br />
          2018-3DTV-Conference: 3D at any scale and any perspective (3DTV-CON),<br />
          2018. <a href="https://doi.org/10.1109/3DTV.2018.8478431">doi:10.1109/3DTV.2018.8478431</a></p>
      </div>
      <div class="tiles-width meta">
        <div class="share">
          <link href="/assets/css/sharing-buttons.css" rel="stylesheet" type="text/css">
          <!-- Sharingbutton Twitter -->
          <a class="resp-sharing-button__link"
   href="https://twitter.com/intent/tweet/?text=Temporal shift estimation for stereoscopic videos&amp;url=
http://localhost:4000/stereo_quality/temporal-shift-estimation.html
"
   target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton Telegram -->
          <a aria-label=""
   class="resp-sharing-button__link"
   href="https://telegram.me/share/url?text=Temporal shift estimation for stereoscopic videos&amp;url=
http://localhost:4000/stereo_quality/temporal-shift-estimation.html
" rel="noopener" target="_blank">
            <div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M.707 8.475C.275 8.64 0 9.508 0 9.508s.284.867.718 1.03l5.09 1.897 1.986 6.38a1.102 1.102 0 0 0 1.75.527l2.96-2.41a.405.405 0 0 1 .494-.013l5.34 3.87a1.1 1.1 0 0 0 1.046.135 1.1 1.1 0 0 0 .682-.803l3.91-18.795A1.102 1.102 0 0 0 22.5.075L.706 8.475z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton Facebook -->
          <a aria-label=""
   class="resp-sharing-button__link"
   href="https://facebook.com/sharer/sharer.php?u=
http://localhost:4000/stereo_quality/temporal-shift-estimation.html
" rel="noopener"
   target="_blank">
            <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M18.77 7.46H14.5v-1.9c0-.9.6-1.1 1-1.1h3V.5h-4.33C10.24.5 9.5 3.44 9.5 5.32v2.15h-3v4h3v12h5v-12h3.85l.42-4z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton E-Mail -->
          <a class="resp-sharing-button__link"
   href="mailto:?subject=Temporal shift estimation for stereoscopic videos&amp;body=
http://localhost:4000/stereo_quality/temporal-shift-estimation.html
" target="_self" rel="noopener"
   aria-label="">
            <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M22 4H2C.9 4 0 4.9 0 6v12c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zM7.25 14.43l-3.5 2c-.08.05-.17.07-.25.07-.17 0-.34-.1-.43-.25-.14-.24-.06-.55.18-.68l3.5-2c.24-.14.55-.06.68.18.14.24.06.55-.18.68zm4.75.07c-.1 0-.2-.03-.27-.08l-8.5-5.5c-.23-.15-.3-.46-.15-.7.15-.22.46-.3.7-.14L12 13.4l8.23-5.32c.23-.15.54-.08.7.15.14.23.07.54-.16.7l-8.5 5.5c-.08.04-.17.07-.27.07zm8.93 1.75c-.1.16-.26.25-.43.25-.08 0-.17-.02-.25-.07l-3.5-2c-.24-.13-.32-.44-.18-.68s.44-.32.68-.18l3.5 2c.24.13.32.44.18.68z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton LinkedIn -->
          <a class="resp-sharing-button__link"
   href="https://www.linkedin.com/shareArticle?mini=true&amp;url=
http://localhost:4000/stereo_quality/temporal-shift-estimation.html
&amp;title=Temporal shift estimation for stereoscopic videos&amp;summary=Temporal shift estimation for stereoscopic videos&amp;source=
http://localhost:4000/stereo_quality/temporal-shift-estimation.html
"
   target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"/>
              </svg>
            </div>
          </a>
        </div>
        <span class="date">05 May 2020</span>
      </div>
      <div class="tiles-width separator"></div>
      <div class="tiles-width see-also-title">
        See Also
      </div>
      <div class="tiles wide">
        <a class="tile" href="/benchmarks/deblurring.html">
          <div class="image" style="background-image: url(/assets/img/benchmarks/deblurring/preview.png)"></div>
          <div class="title">MSU Video Deblurring Benchmark 2022</div>
          <div class="text">Learn about the best video deblurring methods and choose the best model</div>
        </a>
        <a class="tile" href="/stereo_quality/report12.html">
          <div class="image" style="background-image: url(/assets/img/vqmt3d/report12/preview-report.png)"></div>
          <div class="title">MSU 3D-video Quality Analysis. Report 12</div>
          <div class="text"></div>
        </a>
        <a class="tile" href="/stereo_quality/report11.html">
          <div class="image" style="background-image: url(/assets/img/vqmt3d/report11/preview-report.png)"></div>
          <div class="title">MSU 3D-video Quality Analysis. Report 11</div>
          <div class="text"></div>
        </a>
        <a class="tile" href="/stereo_quality/report10.html">
          <div class="image" style="background-image: url(/assets/img/vqmt3d/report10/preview-report.png)"></div>
          <div class="title">MSU 3D-video Quality Analysis. Report 10</div>
          <div class="text"></div>
        </a>
        <a class="tile" href="/stereo_quality/stereo-window-violation.html">
          <div class="image" style="background-image: url(/assets/img/vqmt3d/stereo-window-violation/scheme.png)"></div>
          <div class="title">Detection of stereo window violation</div>
          <div class="text">How to find objects that are present only in one view?</div>
        </a>
        <a class="tile" href="/stereo_quality/depth-continuity-s3d.html">
          <div class="image" style="background-image: url(/assets/img/vqmt3d/depth-continuity-s3d/scheme.png)"></div>
          <div class="title">Depth continuity estimation in S3D video</div>
          <div class="text">How smooth is the depth transition between scenes?</div>
        </a>
      </div>
      <div class="tiles-width separator"></div>
      <div class="tiles-width markdown site-structure">
        <span class="title">Site structure</span>
        <ul>
          <li>
            <a href="/benchmarks/">MSU Benchmark Collection</a>
            <ul>
              <li><a href="/benchmarks/deblurring.html">MSU Video Deblurring Benchmark 2022</a></li>
              <li><a href="/benchmarks/video-frame-interpolation.html">MSU Video Frame Interpolation Benchmark 2022</a></li>
              <li><a href="/benchmarks/video-upscalers.html">MSU Video Upscalers Benchmark 2022</a></li>
              <li><a href="/benchmarks/inverse-tone-mapping.html">MSU HDR Video Reconstruction Benchmark 2022</a></li>
              <li><a href="/benchmarks/super-resolution-for-video-compression.html">MSU Super-Resolution for Video Compression Benchmark 2022</a></li>
              <li><a href="/benchmarks/no-reference-video-quality-metrics.html">MSU No-Reference Video Quality Metrics Benchmark 2022</a></li>
              <li><a href="/benchmarks/full-reference-video-quality-metrics.html">MSU Full-Reference Video Quality Metrics Benchmark 2022</a></li>
              <li><a href="/benchmarks/aligners.html">MSU Video Alignment and Retrieval Benchmark</a></li>
              <li><a href="/benchmarks/mobile-video-codec-benchmark.html">MSU Mobile Video Codecs Benchmark 2021</a></li>
              <li><a href="/benchmarks/video-super-resolution.html">MSU Video Super-Resolution Benchmark</a></li>
              <li><a href="/benchmarks/shot-boundary-detection.html">MSU Shot Boundary Detection Benchmark 2020</a></li>
              <li><a href="/benchmarks/deinterlacer.html">MSU Deinterlacer Benchmark</a></li>
              <li><a href="https://videomatting.com/" target="_blank">The VideoMatting Project</a></li>
              <li><a href="https://videocompletion.org/" target="_blank">Video Completion</a></li>
            </ul>
          </li>
          <li>
            <a href="/codecs/">Codecs Comparisons & Optimization</a>
            <ul>
              <li><a href="/codecs/avc/">AVC Codecs Comparison</a></li>
              <li><a href="/codecs/hevc/">HEVC Codecs Comparison</a></li>
              <li><a href="/codecs/image/">Image Codecs Comparison</a></li>
              <li><a href="/codecs/lossless/">Lossless Codecs Comparison</a></li>
              <li><a href="/codecs/optimization/">Codecs Optimization and Tuning</a></li>
              <li><a href="/codecs/reports/">All Codecs Comparison Reports</a></li>
            </ul>
          </li>
          <li>
            <a href="/vqmt/">VQMT</a>
            <ul>
              <li><a href="/vqmt/plugins/">VQMT Plugins</a></li>
            </ul>
          </li>
          <li>
            <a href="/stereo_quality/">Video Quality Measurement Tool 3D</a>
            <ul>
              <li><a href="/stereo_quality/correction/">Stereo Artifacts Correction</a></li>
              <li><a href="/stereo_quality/metrics/">Stereo Quality Metrics</a></li>
              <li><a href="/stereo_quality/reports/">All Stereo Quality Reports</a></li>
            </ul>
          </li>
          <li>
            <a href="/datasets/">MSU Datasets Collection</a>
            <ul>
            </ul>
          </li>
          <li>
            <a href="/metrics/">Metrics Research</a>
            <ul>
            </ul>
          </li>
          <li>
            <a href="/video_filters/">Video Filters</a>
            <ul>
              <li><a href="/video_filters/image/">Image Processing Filters</a></li>
              <li><a href="/video_filters/public/">Free Filters</a></li>
              <li><a href="/video_filters/virtualdub/">VirtualDub Filters</a></li>
            </ul>
          </li>
          <li>
            <a href="/other/">Other Projects</a>
            <ul>
            </ul>
          </li>
        </ul>
      </div>
    </div>
    <div class="footer">
      <div class="footer-column copyright">
        <img alt="MSU Graphics & Multimedia Lab Video Group" class="logo" src="/assets/img/logo.svg">
        <div class="text">
          MSU Graphics & Media Lab Video Group
          <br>
          2019&ndash;2022
        </div>
      </div>
      <div class="footer-column">
        <ul>
          <li><a href="/codecs/">Codecs Comparisons & Optimization</a></li>
          <li><a href="/vqmt/">VQMT</a></li>
          <li><a href="/stereo_quality/">Video Quality Measurement Tool 3D</a></li>
          <li><a href="/datasets/">MSU Datasets Collection</a></li>
          <li><a href="/metrics/">Metrics Research</a></li>
          <li><a href="/video_filters/">Video Filters</a></li>
          <li><a href="/other/">Other Projects</a></li>
        </ul>
      </div>
      <div class="footer-column">
        <ul>
          <li><a href="/about/">About Us</a></li>
          <li><a href="/benchmarks/">Benchmarks</a></li>
          <li><a href="/projects/">Projects</a></li>
          <li><a href="/publications/">Publications</a></li>
          <li><a href="/contacts/">Contacts</a></li>
        </ul>
      </div>
    </div>
  </body>
</html>