<!DOCTYPE html>
<html lang="en">
  <head prefix="og: https://ogp.me/ns#">
    <link href="/assets/favicon/favicon.ico" rel="shortcut icon">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <title>Forecasting of viewers’ discomfort</title>
    <meta property="og:title" content="Forecasting of viewers’ discomfort">
    <meta property="og:image" content="http://localhost:4000/assets/img/vqmt3d/forecasting-of-viewers-discomfort/preview.jpg">
    <meta name="description" content="How do distortions in a stereo movie affect the discomfort of viewers?">
    <meta property="og:description" content="How do distortions in a stereo movie affect the discomfort of viewers?">
    <meta property="og:url" content="
http://localhost:4000/datasets/mvdsvd.html
">
    <meta property="og:type" content="website">
    <link href="/assets/css/common.css" rel="stylesheet" type="text/css">
    <script src="/assets/js/interface.js"></script>
    <link rel="stylesheet" type="text/css" href="/assets/css/nav_arrow.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>
  <body>
    <ul class="navbar">
      <li class="navbar-header">
        <a href="/" class="header">
          <img alt="Main page" class="logo" src="/assets/img/logo.svg">
          <h1>Video processing, compression<br>
            and quality research group
            <div>Based in MSU Graphics & Media Laboratory</div>
          </h1>
        </a>
        <a class="menu-toggle-button">
          <div class="icon"></div>
        </a>
      </li>
      <li>
        <a href="/benchmarks/">Benchmarks <img class="dropdown-icon" src="/assets/icons/dropdown.svg"></a>
        <ul class="dropmenu">
          <li><a href="/benchmarks/deblurring.html">MSU Video Deblurring Benchmark 2022</a></li>
          <li><a href="/benchmarks/video-frame-interpolation.html">MSU Video Frame Interpolation Benchmark 2022</a></li>
          <li><a href="/benchmarks/video-upscalers.html">MSU Video Upscalers Benchmark 2022</a></li>
          <li><a href="/benchmarks/inverse-tone-mapping.html">MSU HDR Video Reconstruction Benchmark 2022</a></li>
          <li><a href="/benchmarks/super-resolution-for-video-compression.html">MSU Super-Resolution for Video Compression Benchmark 2022</a></li>
          <li><a href="/benchmarks/no-reference-video-quality-metrics.html">MSU No-Reference Video Quality Metrics Benchmark 2022</a></li>
          <li><a href="/benchmarks/full-reference-video-quality-metrics.html">MSU Full-Reference Video Quality Metrics Benchmark 2022</a></li>
          <li><a href="/benchmarks/aligners.html">MSU Video Alignment and Retrieval Benchmark</a></li>
          <li><a href="/benchmarks/mobile-video-codec-benchmark.html">MSU Mobile Video Codecs Benchmark 2021</a></li>
          <li><a href="/benchmarks/video-super-resolution.html">MSU Video Super-Resolution Benchmark</a></li>
          <li><a href="/benchmarks/shot-boundary-detection.html">MSU Shot Boundary Detection Benchmark 2020</a></li>
          <li><a href="/benchmarks/deinterlacer.html">MSU Deinterlacer Benchmark</a></li>
          <li><a href="https://videomatting.com/" target="_blank">The VideoMatting Project</a></li>
          <li><a href="https://videocompletion.org/" target="_blank">Video Completion</a></li>
        </ul>
      </li>
      <li>
        <a href="/projects/">Projects <img class="dropdown-icon" src="/assets/icons/dropdown.svg"></a>
        <ul class="dropmenu">
          <li><a href="/codecs/">Codecs Comparisons & Optimization</a></li>
          <li><a href="/vqmt/">VQMT</a></li>
          <li><a href="/stereo_quality/">Video Quality Measurement Tool 3D</a></li>
          <li><a href="/datasets/">MSU Datasets Collection</a></li>
          <li><a href="/metrics/">Metrics Research</a></li>
          <li><a href="/video_filters/">Video Filters</a></li>
          <li><a href="/other/">Other Projects</a></li>
        </ul>
      </li>
      <li><a href="/publications/">Publications</a></li>
      <li><a href="/about/">About Us</a></li>
      <li><a href="/contacts/">Contacts</a></li>
    </ul>
    <div class="content">
      <link href="/assets/css/post.css" rel="stylesheet" type="text/css">
      <div class="tiles-width nav-current">
        <a href="/index.html">Main page</a> &mdash;
        <a href="/datasets/">MSU Datasets Collection</a>
      </div>
      <div class="tiles-width markdown article">
        <h1 id="forecasting-of-viewers-discomfort">Forecasting of viewers’ discomfort</h1>
        <ul>
          <li>Author: Anastasiia Antsiferova</li>
          <li>Supervisor: dr. Dmitriy Vatolin</li>
        </ul>
        <h2 id="introduction">Introduction</h2>
        <p>Nowadays, numerous movies are produced in stereoscopic format. Despite the development of stereoscopic movie production, stereoscopic artifacts causing discomfort right up to headaches continue to appear even in high-budget movies.</p>
        <p>In this study, the influence of geometric, color and temporal artifacts was examined.</p>
        <p><img src="/assets/img/vqmt3d/forecasting-of-viewers-discomfort/distortions.png" alt="Distortions" /></p>
        <h2 id="experiments">Experiments</h2>
        <p>In a series of experiments, participants were asked to evaluate the level of discomfort while watching a specially prepared stereoscopic video. Over 300 people took part.</p>
        <p><b>Experiment comparison</b></p>
        <link href="/assets/css/vqmt3d/style.css" rel="stylesheet" type="text/css" />
        <style type="text/css">
          .fixed-container {
              overflow: auto;
          }
          
          .fancytable {
              border-spacing: 0;
              width: 100%;
          }
          
          .col2 td:nth-child(2),
          .col3 td:nth-child(3),
          .col4 td:nth-child(4),
          .col5 td:nth-child(5),
          .col6 td:nth-child(6),
          .col7 td:nth-child(7),
          .col8 td:nth-child(8),
          .col9 td:nth-child(9) { text-align: center; }
        </style>
        <div class="fixed-container full-bleed">
          <table class="fancytable table-fixed col2 col3 col4 col5 col6 col7 col8 col9" style="display: table">
            <thead>
              <tr>
                <th>University</th>
                <th>#subjects</th>
                <th>#subjects per video</th>
                <th>Duration</th>
                <th>#videos</th>
                <th>#videos per test</th>
                <th>#scores</th>
                <th>Year</th>
                <th>3D tech.</th>
                <th>Stimuli</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><a href="https://doi.org/10.1109/3DTV.2010.5506331">University of Surrey</a></td>
                <td>30</td>
                <td>30</td>
                <td>25</td>
                <td>40</td>
                <td>40</td>
                <td>1200</td>
                <td>2010</td>
                <td>Autostereo.</td>
                <td>Synthetic S3D seq., encoding with different QP</td>
              </tr>
              <tr>
                <td><a href="https://www.semanticscholar.org/paper/An-Assessment-of-Visual-Discomfort-Caused-by-in-3D-Cho-Kang/c490e2c57d8626b1c012db180bd1c757efaf01bf">Catholic University of Korea</a></td>
                <td>20</td>
                <td>20</td>
                <td>18</td>
                <td>36</td>
                <td>36</td>
                <td>720</td>
                <td>2011</td>
                <td>Passive</td>
                <td>Captured S3D seq., different parallax and motion</td>
              </tr>
              <tr>
                <td><a href="https://hal.archives-ouvertes.fr/hal-00724563/">Telecom Innovation Labs</a></td>
                <td>24</td>
                <td>24</td>
                <td>50</td>
                <td>64</td>
                <td>64</td>
                <td>1536</td>
                <td>2011</td>
                <td>Active</td>
                <td>Open S3D DB, different parallax</td>
              </tr>
              <tr>
                <td><a href="https://doi.org/10.1016/j.displa.2011.05.012">Philips Research Labs</a></td>
                <td>24</td>
                <td>24</td>
                <td>24</td>
                <td>7</td>
                <td>7</td>
                <td>168</td>
                <td>2011</td>
                <td>Autostereo.</td>
                <td>3D movie (converted), different parallax</td>
              </tr>
              <tr>
                <td><a href="https://onlinelibrary.wiley.com/doi/full/10.1111/aos.12006">Beijing Institute of Ophthal.</a></td>
                <td>30</td>
                <td>30</td>
                <td>30</td>
                <td>1</td>
                <td>1</td>
                <td>30</td>
                <td>2012</td>
                <td>Active+passive</td>
                <td>3D movie (captured)</td>
              </tr>
              <tr>
                <td><a href="https://hal.archives-ouvertes.fr/hal-00717865/">LUNAM University</a></td>
                <td>29</td>
                <td>29</td>
                <td>28</td>
                <td>110</td>
                <td>110</td>
                <td>3190</td>
                <td>2012</td>
                <td>Active</td>
                <td>Open S3D DB (NAMA3DS1-COSPAD1),<br />
                  different degradations</td>
              </tr>
              <tr>
                <td><a href="https://www.researchgate.net/publication/271488946_Towards_standardized_3DTV_QoE_assessment_Cross-lab_study_on_display_technology_and_viewing_environment_parameters">Yonsei University</a></td>
                <td>28</td>
                <td>28</td>
                <td>29</td>
                <td>110</td>
                <td>110</td>
                <td>3080</td>
                <td>2013</td>
                <td>Passive</td>
                <td>Open S3D DB,10 degradation types</td>
              </tr>
              <tr>
                <td><a href="https://www.researchgate.net/publication/271488946_Towards_standardized_3DTV_QoE_assessment_Cross-lab_study_on_display_technology_and_viewing_environment_parameters">Acreo Institute</a></td>
                <td>48</td>
                <td>28</td>
                <td>29</td>
                <td>110</td>
                <td>110</td>
                <td>5280</td>
                <td>2013</td>
                <td>Passive</td>
                <td>Open S3D DB,10 degradation types</td>
              </tr>
              <tr>
                <td><a href="https://link.springer.com/article/10.1007/s11760-013-0439-0">Tampere University of Tech.</a></td>
                <td>10</td>
                <td>10</td>
                <td>45</td>
                <td>40</td>
                <td>40</td>
                <td>400</td>
                <td>2013</td>
                <td>Passive</td>
                <td>Captured S3D seq., encoding with different QP</td>
              </tr>
              <tr>
                <td><a href="https://www.researchgate.net/publication/272196362_Visual_discomfort_while_watching_stereoscopic_three-dimensional_movies_at_the_cinema">Roma Tre University</a></td>
                <td>854</td>
                <td>43-255</td>
                <td>90</td>
                <td>-</td>
                <td>1</td>
                <td>854</td>
                <td>2014</td>
                <td>Passive</td>
                <td>Screening after watching S3D movies in cinemas</td>
              </tr>
              <tr>
                <td><a href="http://live.ece.utexas.edu/publications/2014/MISCQ%20TMM.pdf">Yonsei University</a></td>
                <td>56</td>
                <td>56</td>
                <td>10.5</td>
                <td>30.1</td>
                <td>31</td>
                <td>1736</td>
                <td>2014</td>
                <td>Autostereo.</td>
                <td>Open S3D DB, different SI and TI</td>
              </tr>
              <tr>
                <td><a href="http://www.eeng.dcu.ie/~munteang/papers/2015_ICCW_YH.pdf">University College Dublin</a></td>
                <td>40</td>
                <td>4</td>
                <td>5.5</td>
                <td>25.11</td>
                <td>33</td>
                <td>1320</td>
                <td>2015</td>
                <td>Active</td>
                <td>Open S3D DB, packet losses</td>
              </tr>
              <tr>
                <td><a href="https://arxiv.org/abs/1803.04832">University of British Columbia</a></td>
                <td>88</td>
                <td>88</td>
                <td>48</td>
                <td>208</td>
                <td>208</td>
                <td>18304</td>
                <td>2015</td>
                <td>Passive</td>
                <td>Open S3D DB, different SI/TI and compression degradations</td>
              </tr>
              <tr>
                <td><a href="https://link.springer.com/article/10.1007/s11042-015-3172-6">University North</a></td>
                <td>146</td>
                <td>18</td>
                <td>8</td>
                <td>184</td>
                <td>26</td>
                <td>146</td>
                <td>2016</td>
                <td>Active</td>
                <td>Open S3D DB, 22 degradation types<br />
                  (packet losses, encoding, resizing,<br />
                  disparity, brightness, geometry etc.)</td>
              </tr>
              <tr>
                <td><a href="https://api.semanticscholar.org/CorpusID:6725639">University of Coimbra</a></td>
                <td>35</td>
                <td>2-6</td>
                <td>7-1</td>
                <td>184</td>
                <td>26</td>
                <td>146</td>
                <td>2016</td>
                <td>Active</td>
                <td>Open S3D DB, 22 degradation types<br />
                  (packet losses, encoding, resizing,<br />
                  disparity, brightness, geometry etc.)</td>
              </tr>
              <tr>
                <td><strong><a href="/stereo_quality/forecasting-of-viewers-discomfort.html">Lomonosov MSU</a></strong></td>
                <td><strong>302</strong></td>
                <td><strong>370</strong></td>
                <td><strong>40</strong></td>
                <td><strong>60</strong></td>
                <td><strong>60</strong></td>
                <td><strong>22200</strong></td>
                <td><strong>2017</strong></td>
                <td><strong>Passive</strong></td>
                <td><strong>Scenes from 3D movies (captured), 4 types of S3D distortions,<br />
                    5 intensities</strong></td>
              </tr>
            </tbody>
          </table>
        </div>
        <p><b>Experiment process</b></p>
        <p><img src="/assets/img/vqmt3d/forecasting-of-viewers-discomfort/experiment_process.jpg" alt="Experiment process" /></p>
        <p><img src="/assets/img/vqmt3d/forecasting-of-viewers-discomfort/experiment_process1.jpg" alt="Experiment process" /></p>
        <p><img src="/assets/img/vqmt3d/forecasting-of-viewers-discomfort/glasses.jpg" alt="Experiment process" /></p>
        <p><br />
          <b>Discomfort level sorted by mean discomfort (red for high)</b></p>
        <p><img src="/assets/img/vqmt3d/forecasting-of-viewers-discomfort/experiment_results.png" alt="Experiment results" /></p>
        <p>Here “C” is the color mismatch between stereoscopic views, “R” is the rotation mismatch, “T” is the temporal shift and “S” is the scale mismatch. The distortion intensity is indicated by numbers from 0 to 4, where 0 corresponds to the absence of distortion (the original scene was demonstrated).</p>
        <p>To solve the problem of assessing the discomfort level, we used machine learning algorithms on the processed experimental data. More than 30,000 configurations were tested on the obtained stratified cross-validation dataset.</p>
        <p>The best result was shown by a linear regression model with the Huber loss function and L2–regularization.</p>
        <h2 id="results">Results</h2>
        <p>The proposed models were applied to evaluate 60 stereoscopic movies.</p>
        <p>The predicted level of discomfort that viewers may experience and the predicted percentage of viewers who will probably feel the discomfort while watching the analyzed movies are illustrated below:</p>
        <p><img src="/assets/img/vqmt3d/forecasting-of-viewers-discomfort/level_of_discomfort.png" alt="Level of discomfort" /></p>
        <p><img src="/assets/img/vqmt3d/forecasting-of-viewers-discomfort/percentage_of_viewers.png" alt="Percentage of viewers" /></p>
        <h2 id="dataset">Dataset</h2>
        <div>
          <p>Dataset consists of 60 video fragments that have been viewed and evaluated by a group of 302 people</p>
          <p>p-13 folder consists of:</p>
          <ul>
            <li>File with viewing order (direct and backward)</li>
            <li>60 subfolders, each contains video fragment, it's grade and information about distortions in the video</li>
          </ul>
        </div>
        <h2 id="downloads">Downloads</h2>
        <p><strong>IC3D Paper (2017)</strong></p>
        <p>Accepted version of the paper:
          <a href="https://istina.msu.ru/download/97061755/1lf2EL:KCwkYw3pX5NDJn_FigG78uGV3KE/">Download</a></p>
        <p>Dataset:
          <a href="https://www.dropbox.com/s/m9v8fha815rwa91/msu-stereo-dataset-p13.zip?dl=0">Download</a></p>
        <h2 id="reference">Reference</h2>
        <p><strong>Citation</strong>
          A. Antsiferova, D. Vatolin.
          <em>“The influence of 3D video artifacts on discomfort of 302 viewers”</em>.
          <strong>2017 IEEE International Conference on 3D Immersion (IC3D)</strong>. pp. 1-8.</p>
        <p><strong>Bibtex</strong></p>
        <div class="highlighter-rouge">
          <div class="highlight">
            <pre class="highlight"><code>    @inproceedings{antsiferova2017influence,
    title={The influence of 3D video artifacts on discomfort of 302 viewers},
    author={Antsiferova, Anastasia and Vatolin, D},
    booktitle={2017 International Conference on 3D Immersion (IC3D)},
    pages={1--8},
    year={2017},
    organization={IEEE}
    }
</code></pre>
          </div>
        </div>
      </div>
      <div class="tiles-width meta">
        <div class="share">
          <link href="/assets/css/sharing-buttons.css" rel="stylesheet" type="text/css">
          <!-- Sharingbutton Twitter -->
          <a class="resp-sharing-button__link"
   href="https://twitter.com/intent/tweet/?text=Forecasting of viewers’ discomfort&amp;url=
http://localhost:4000/datasets/mvdsvd.html
"
   target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton Telegram -->
          <a aria-label=""
   class="resp-sharing-button__link"
   href="https://telegram.me/share/url?text=Forecasting of viewers’ discomfort&amp;url=
http://localhost:4000/datasets/mvdsvd.html
" rel="noopener" target="_blank">
            <div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M.707 8.475C.275 8.64 0 9.508 0 9.508s.284.867.718 1.03l5.09 1.897 1.986 6.38a1.102 1.102 0 0 0 1.75.527l2.96-2.41a.405.405 0 0 1 .494-.013l5.34 3.87a1.1 1.1 0 0 0 1.046.135 1.1 1.1 0 0 0 .682-.803l3.91-18.795A1.102 1.102 0 0 0 22.5.075L.706 8.475z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton Facebook -->
          <a aria-label=""
   class="resp-sharing-button__link"
   href="https://facebook.com/sharer/sharer.php?u=
http://localhost:4000/datasets/mvdsvd.html
" rel="noopener"
   target="_blank">
            <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M18.77 7.46H14.5v-1.9c0-.9.6-1.1 1-1.1h3V.5h-4.33C10.24.5 9.5 3.44 9.5 5.32v2.15h-3v4h3v12h5v-12h3.85l.42-4z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton E-Mail -->
          <a class="resp-sharing-button__link"
   href="mailto:?subject=Forecasting of viewers’ discomfort&amp;body=
http://localhost:4000/datasets/mvdsvd.html
" target="_self" rel="noopener"
   aria-label="">
            <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M22 4H2C.9 4 0 4.9 0 6v12c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zM7.25 14.43l-3.5 2c-.08.05-.17.07-.25.07-.17 0-.34-.1-.43-.25-.14-.24-.06-.55.18-.68l3.5-2c.24-.14.55-.06.68.18.14.24.06.55-.18.68zm4.75.07c-.1 0-.2-.03-.27-.08l-8.5-5.5c-.23-.15-.3-.46-.15-.7.15-.22.46-.3.7-.14L12 13.4l8.23-5.32c.23-.15.54-.08.7.15.14.23.07.54-.16.7l-8.5 5.5c-.08.04-.17.07-.27.07zm8.93 1.75c-.1.16-.26.25-.43.25-.08 0-.17-.02-.25-.07l-3.5-2c-.24-.13-.32-.44-.18-.68s.44-.32.68-.18l3.5 2c.24.13.32.44.18.68z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton LinkedIn -->
          <a class="resp-sharing-button__link"
   href="https://www.linkedin.com/shareArticle?mini=true&amp;url=
http://localhost:4000/datasets/mvdsvd.html
&amp;title=Forecasting of viewers’ discomfort&amp;summary=Forecasting of viewers’ discomfort&amp;source=
http://localhost:4000/datasets/mvdsvd.html
"
   target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"/>
              </svg>
            </div>
          </a>
        </div>
        <span class="date">07 May 2021</span>
      </div>
      <div class="tiles-width separator"></div>
      <div class="tiles-width see-also-title">
        See Also
      </div>
      <div class="tiles wide">
        <a class="tile" href="/benchmarks/deblurring.html">
          <div class="image" style="background-image: url(/assets/img/benchmarks/deblurring/preview.png)"></div>
          <div class="title">MSU Video Deblurring Benchmark 2022</div>
          <div class="text">Learn about the best video deblurring methods and choose the best model</div>
        </a>
        <a class="tile" href="/datasets/savam.html">
          <div class="image" style="background-image: url(/assets/img/datasets/savam/image1_nocr_our.png)"></div>
          <div class="title">SAVAM - the database</div>
          <div class="text">During our work we have created the database of human eye-movements captured while viewing various videos</div>
        </a>
        <a class="tile" href="/benchmarks/video-frame-interpolation.html">
          <div class="image" style="background-image: url(/assets/img/benchmarks/vfi/main.webp)"></div>
          <div class="title">MSU Video Frame Interpolation Benchmark 2022</div>
          <div class="text">Discover the best algorithm to make high-quality and smooth slow motion videos</div>
        </a>
      </div>
      <div class="tiles-width separator"></div>
      <div class="tiles-width markdown site-structure">
        <span class="title">Site structure</span>
        <ul>
          <li>
            <a href="/benchmarks/">MSU Benchmark Collection</a>
            <ul>
              <li><a href="/benchmarks/deblurring.html">MSU Video Deblurring Benchmark 2022</a></li>
              <li><a href="/benchmarks/video-frame-interpolation.html">MSU Video Frame Interpolation Benchmark 2022</a></li>
              <li><a href="/benchmarks/video-upscalers.html">MSU Video Upscalers Benchmark 2022</a></li>
              <li><a href="/benchmarks/inverse-tone-mapping.html">MSU HDR Video Reconstruction Benchmark 2022</a></li>
              <li><a href="/benchmarks/super-resolution-for-video-compression.html">MSU Super-Resolution for Video Compression Benchmark 2022</a></li>
              <li><a href="/benchmarks/no-reference-video-quality-metrics.html">MSU No-Reference Video Quality Metrics Benchmark 2022</a></li>
              <li><a href="/benchmarks/full-reference-video-quality-metrics.html">MSU Full-Reference Video Quality Metrics Benchmark 2022</a></li>
              <li><a href="/benchmarks/aligners.html">MSU Video Alignment and Retrieval Benchmark</a></li>
              <li><a href="/benchmarks/mobile-video-codec-benchmark.html">MSU Mobile Video Codecs Benchmark 2021</a></li>
              <li><a href="/benchmarks/video-super-resolution.html">MSU Video Super-Resolution Benchmark</a></li>
              <li><a href="/benchmarks/shot-boundary-detection.html">MSU Shot Boundary Detection Benchmark 2020</a></li>
              <li><a href="/benchmarks/deinterlacer.html">MSU Deinterlacer Benchmark</a></li>
              <li><a href="https://videomatting.com/" target="_blank">The VideoMatting Project</a></li>
              <li><a href="https://videocompletion.org/" target="_blank">Video Completion</a></li>
            </ul>
          </li>
          <li>
            <a href="/codecs/">Codecs Comparisons & Optimization</a>
            <ul>
              <li><a href="/codecs/avc/">AVC Codecs Comparison</a></li>
              <li><a href="/codecs/hevc/">HEVC Codecs Comparison</a></li>
              <li><a href="/codecs/image/">Image Codecs Comparison</a></li>
              <li><a href="/codecs/lossless/">Lossless Codecs Comparison</a></li>
              <li><a href="/codecs/optimization/">Codecs Optimization and Tuning</a></li>
              <li><a href="/codecs/reports/">All Codecs Comparison Reports</a></li>
            </ul>
          </li>
          <li>
            <a href="/vqmt/">VQMT</a>
            <ul>
              <li><a href="/vqmt/plugins/">VQMT Plugins</a></li>
            </ul>
          </li>
          <li>
            <a href="/stereo_quality/">Video Quality Measurement Tool 3D</a>
            <ul>
              <li><a href="/stereo_quality/correction/">Stereo Artifacts Correction</a></li>
              <li><a href="/stereo_quality/metrics/">Stereo Quality Metrics</a></li>
              <li><a href="/stereo_quality/reports/">All Stereo Quality Reports</a></li>
            </ul>
          </li>
          <li>
            <a href="/datasets/">MSU Datasets Collection</a>
            <ul>
            </ul>
          </li>
          <li>
            <a href="/metrics/">Metrics Research</a>
            <ul>
            </ul>
          </li>
          <li>
            <a href="/video_filters/">Video Filters</a>
            <ul>
              <li><a href="/video_filters/image/">Image Processing Filters</a></li>
              <li><a href="/video_filters/public/">Free Filters</a></li>
              <li><a href="/video_filters/virtualdub/">VirtualDub Filters</a></li>
            </ul>
          </li>
          <li>
            <a href="/other/">Other Projects</a>
            <ul>
            </ul>
          </li>
        </ul>
      </div>
    </div>
    <div class="footer">
      <div class="footer-column copyright">
        <img alt="MSU Graphics & Multimedia Lab Video Group" class="logo" src="/assets/img/logo.svg">
        <div class="text">
          MSU Graphics & Media Lab Video Group
          <br>
          2019&ndash;2022
        </div>
      </div>
      <div class="footer-column">
        <ul>
          <li><a href="/codecs/">Codecs Comparisons & Optimization</a></li>
          <li><a href="/vqmt/">VQMT</a></li>
          <li><a href="/stereo_quality/">Video Quality Measurement Tool 3D</a></li>
          <li><a href="/datasets/">MSU Datasets Collection</a></li>
          <li><a href="/metrics/">Metrics Research</a></li>
          <li><a href="/video_filters/">Video Filters</a></li>
          <li><a href="/other/">Other Projects</a></li>
        </ul>
      </div>
      <div class="footer-column">
        <ul>
          <li><a href="/about/">About Us</a></li>
          <li><a href="/benchmarks/">Benchmarks</a></li>
          <li><a href="/projects/">Projects</a></li>
          <li><a href="/publications/">Publications</a></li>
          <li><a href="/contacts/">Contacts</a></li>
        </ul>
      </div>
    </div>
  </body>
</html>