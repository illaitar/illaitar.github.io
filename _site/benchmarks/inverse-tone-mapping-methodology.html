<!DOCTYPE html>
<html lang="en">
  <head prefix="og: https://ogp.me/ns#">
    <link href="/assets/favicon/favicon.ico" rel="shortcut icon">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="UTF-8">
    <title>MSU HDR Video Reconstruction Benchmark Methodology</title>
    <meta property="og:title" content="MSU HDR Video Reconstruction Benchmark Methodology">
    <meta property="og:image" content="http://localhost:4000/assets/img/logo.svg">
    <meta name="description" content="Evaluation Methodology of MSU HDR Video Reconstruction Benchmark">
    <meta property="og:description" content="Evaluation Methodology of MSU HDR Video Reconstruction Benchmark">
    <meta property="og:url" content="
http://localhost:4000/benchmarks/inverse-tone-mapping-methodology.html
">
    <meta property="og:type" content="website">
    <link href="/assets/css/common.css" rel="stylesheet" type="text/css">
    <script src="/assets/js/interface.js"></script>
    <link rel="stylesheet" type="text/css" href="/assets/css/nav_arrow.css" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  </head>
  <body>
    <ul class="navbar">
      <li class="navbar-header">
        <a href="/" class="header">
          <img alt="Main page" class="logo" src="/assets/img/logo.svg">
          <h1>Video processing, compression<br>
            and quality research group
            <div>Based in MSU Graphics & Media Laboratory</div>
          </h1>
        </a>
        <a class="menu-toggle-button">
          <div class="icon"></div>
        </a>
      </li>
      <li>
        <a href="/benchmarks/">Benchmarks <img class="dropdown-icon" src="/assets/icons/dropdown.svg"></a>
        <ul class="dropmenu">
          <li><a href="/benchmarks/deblurring.html">MSU Video Deblurring Benchmark 2022</a></li>
          <li><a href="/benchmarks/video-frame-interpolation.html">MSU Video Frame Interpolation Benchmark 2022</a></li>
          <li><a href="/benchmarks/video-upscalers.html">MSU Video Upscalers Benchmark 2022</a></li>
          <li><a href="/benchmarks/inverse-tone-mapping.html">MSU HDR Video Reconstruction Benchmark 2022</a></li>
          <li><a href="/benchmarks/super-resolution-for-video-compression.html">MSU Super-Resolution for Video Compression Benchmark 2022</a></li>
          <li><a href="/benchmarks/no-reference-video-quality-metrics.html">MSU No-Reference Video Quality Metrics Benchmark 2022</a></li>
          <li><a href="/benchmarks/full-reference-video-quality-metrics.html">MSU Full-Reference Video Quality Metrics Benchmark 2022</a></li>
          <li><a href="/benchmarks/aligners.html">MSU Video Alignment and Retrieval Benchmark</a></li>
          <li><a href="/benchmarks/mobile-video-codec-benchmark.html">MSU Mobile Video Codecs Benchmark 2021</a></li>
          <li><a href="/benchmarks/video-super-resolution.html">MSU Video Super-Resolution Benchmark</a></li>
          <li><a href="/benchmarks/shot-boundary-detection.html">MSU Shot Boundary Detection Benchmark 2020</a></li>
          <li><a href="/benchmarks/deinterlacer.html">MSU Deinterlacer Benchmark</a></li>
          <li><a href="https://videomatting.com/" target="_blank">The VideoMatting Project</a></li>
          <li><a href="https://videocompletion.org/" target="_blank">Video Completion</a></li>
        </ul>
      </li>
      <li>
        <a href="/projects/">Projects <img class="dropdown-icon" src="/assets/icons/dropdown.svg"></a>
        <ul class="dropmenu">
          <li><a href="/codecs/">Codecs Comparisons & Optimization</a></li>
          <li><a href="/vqmt/">VQMT</a></li>
          <li><a href="/stereo_quality/">Video Quality Measurement Tool 3D</a></li>
          <li><a href="/datasets/">MSU Datasets Collection</a></li>
          <li><a href="/metrics/">Metrics Research</a></li>
          <li><a href="/video_filters/">Video Filters</a></li>
          <li><a href="/other/">Other Projects</a></li>
        </ul>
      </li>
      <li><a href="/publications/">Publications</a></li>
      <li><a href="/about/">About Us</a></li>
      <li><a href="/contacts/">Contacts</a></li>
    </ul>
    <div class="content">
      <link href="/assets/css/post.css" rel="stylesheet" type="text/css">
      <div class="tiles-width nav-current">
        <a href="/index.html">Main page</a> &mdash;
        <a href="/benchmarks/">MSU Benchmark Collection</a>
      </div>
      <div class="tiles-width markdown article">
        <link rel="stylesheet" href="/assets/css/benchmarks/style.css" />
        <script src="https://code.highcharts.com/highcharts.js"></script>
        <script src="https://code.highcharts.com/modules/exporting.js"></script>
        <script src="https://code.highcharts.com/modules/export-data.js"></script>
        <script src="https://code.highcharts.com/modules/accessibility.js"></script>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
        <script src="https://code.highcharts.com/highcharts-more.js"></script>
        <link rel="stylesheet" type="text/css" href="https://cdn.datatables.net/1.10.22/css/jquery.dataTables.css" />
        <script type="text/javascript" charset="utf8" src="https://cdn.datatables.net/1.10.22/js/jquery.dataTables.js"></script>
        <h1 id="evaluation-methodology-of-msu-hdr-video-reconstruction-benchmark-2022-hlg">Evaluation Methodology of MSU HDR Video Reconstruction Benchmark 2022: HLG</h1>
        <div id="buttons"></div>
        <script>
          __set_menu_buttons([
          ['Home', '/benchmarks/inverse-tone-mapping.html'],
          ['Participants','/benchmarks/inverse-tone-mapping-participants.html'],
              ['Dataset', '/benchmarks/inverse-tone-mapping-dataset.html'],
          ['Evaluation methodology', '/benchmarks/inverse-tone-mapping-methodology.html'],
              ['Contact us', '/benchmarks/inverse-tone-mapping.html#contacts']
          ], 'Evaluation methodology')
        </script>
        <div class="current_content">
          <h2 id="problem-definition">Problem Definition</h2>
          <p>High Dynamic Range (HDR) reconstruction is the process of obtaining HDR photos or videos from their standard dynamic range (SDR) versions. This problem can be approached in different ways, and the purpose of this particular benchmark is to find the best method of HDR video restoration in terms of human evaluation.
            In the context of video restoration, it is important not only to restore the brightness of the pixels, but also to increase the bit rate and expand the color space.</p>
          <h2 id="why-do-we-need-pq-and-hlg">Why do we need PQ and HLG?</h2>
          <p><a href="https://en.wikipedia.org/wiki/Perceptual_quantizer">What is PQ?</a><br />
            <a href="https://en.wikipedia.org/wiki/Hybrid_log–gamma">What is HLG?</a><br />
          </p>
          <p>These gamma curves are the most popular and are used in different cases. HLG is used in television broadcasting. PQ for showing movies.
            Since these curves are significantly different, they preserve details differently in different brightness levels. In addition, HLG partially repeats the usual Rec.709 gamut, so video recovery for it may be easier.
            Please note that we use PQ to calculate some metrics, despite the fact that the purpose of the recovery is HLG. This is done because this gamma curve better reflects a person’s perception of brightness, which results in a greater correlation of metrics with subjective assessments.
            At the moment, we have published a study of only the HLG part.<br />
            <strong>The part with the study of PQ-HDR video reconstruction will be published soon.</strong></p>
          <h2 id="dataset">Dataset</h2>
          <p>We present a <strong>new private dataset</strong> for this comparison. This was done to ensure that neural network methods do not benefit from training on data that could get into our test sample. The authors of the article <a href="https://openaccess.thecvf.com/content/ICCV2021W/LCI/papers/Eilertsen_How_To_Cheat_With_Metrics_in_Single-Image_HDR_Reconstruction_ICCVW_2021_paper.pdf">“How to cheat with metrics in single-image HDR reconstruction”</a> describe this problem in detail. Here we provide the key characteristics of Dataset.<br />
          </p>
          <p>
            <img width="50%" src="https://storage.videoprocessing.ai/benchmarks/itm/visualizations/info/dataset_info.webp" />
          </p>
          <p>SDR* – tonemapped HDR video</p>
          <p>More details about Dataset characteristics and processing you can find in <a href="/benchmarks/inverse-tone-mapping-dataset.html">Dataset tab</a>.</p>
          <h2 id="metrics">Metrics</h2>
          <p align="center">
            <img width="100%" src="https://storage.videoprocessing.ai/benchmarks/itm/visualizations/info/metrics.webp" />
          </p>
          <p>References:<br />
          </p>
          <ul>
            <li><a href="https://compression.ru/video/quality_measure/video_measurement_tool.html">MSU VQMT</a><br />
            </li>
            <li><a href="https://github.com/gfxdisp/FovVideoVDP">FovVideoVDP</a><br />
            </li>
            <li><a href="https://sourceforge.net/projects/hdrvdp/files/hdrvdp/3.0.6/">HDR-VDP-3</a><br />
            </li>
          </ul>
          <h2 id="evaluation">Evaluation</h2>
          <h3 id="splitting-into-frames">Splitting into frames</h3>
          <p>Each SDR video was divided into frames with the command<br />
          </p>
          <div class="language-shell highlighter-rouge">
            <div class="highlight">
              <pre class="highlight"><code>ffmpeg <span class="nt">-i</span> <span class="k">in</span>.mov %04d.png
</code></pre>
            </div>
              </div>
          <p>This was done due to the fact that all (except <a href="https://www.maxon.net/en/red-giant-complete/magic-bullet-suite/colorista">Maxon</a> at the moment) methods take individual images as input.
            In all methods, where it is possible to set the option to restore video, it was set.</p>
          <h3 id="video-generation">Video generation</h3>
          <p>Different methods are trained to give output video frames in different formats. The target format of our benchmark:</p>
          <ul>
            <li>Maximum brightness: 1000 nits</li>
            <li>Color space: Rec.2020<br />
            </li>
          </ul>
          <p>Therefore, for each algorithm the output was processed individually with <strong>Davinci Resolve 17</strong> using the built-in Color Space Transform tool.<br />
            We use Color Space Transform twice: for encoding with the HLG gamma curve and for encoding with the PQ gamma curve. We use the first one as a preparation for the future subjective comparison. The second one is used for metrics calculations.<br />
            We use gamma curve PQ instead of HLG to calculate metrics because it was shown in the studies that this approach allows to calculate metrics that were developed for SDR content in the most correct way.<br />
            The details of the output of each method are described below. Each bullet describes the process of converting the luminance and color space to the one we require. As mentioned above, after that we encode the video with two different gamma curves.</p>
          <ul>
            <li>
              <p><strong>HDR-CNN, ExpNet, DeepHDR</strong><br />
                These methods predict relative HDR luminance values in the range [0,1] with a linear gamma curve and do not change the color space.
                We use Luminance Mapping to map the value of 1 (which corresponds to 100 nit) to 1000 nit. Since the output of these methods is in 32-bit .exr format, this conversion does not produce banding if the low bits are filled with significant information.
                We also change the color space, since these methods do not restore Rec.2020.</p>
            </li>
            <li>
              <p><strong>SingleHDR, HDRToolbox</strong>*<br />
                The output frames of these methods are in linear gamma and have absolute luminance values in the range [0, 10000] nit. So we use Luminance Mapping from 10000 nit to 1000 nit and change the color space to Rec.2020.</p>
            </li>
            <li>
              <p><strong>Maxon</strong><br />
                For testing the “Highlight Boost” option was set to the maximum value (100), then the standard video export procedure was performed.</p>
            </li>
            <li>
              <p><strong>HDRTVNet</strong><br />
                This method is specifically designed to restore a video with a PQ gamma curve. Since the default luminance values for this curve are 10000 nit we used Luminance Mapping from 10000 nit to 1000 nit. We do not change the color space for this method since its output is already in Rec.2020.</p>
            </li>
            <li>
              <p><strong>GT</strong><br />
                Since the camera we shot the dataset with applies the ITU-R BT.2100 HLG gamma curve, we re-encode the video to “SMPTE ST 2084 1000 nit” in order to calculate the metrics.</p>
            </li>
          </ul>
          <p>On pictures below you can see all Color Space Transform settings:
            <br />
          </p>
          <div class="kkk">
            <div class="hhh">
              <img src="https://storage.videoprocessing.ai/benchmarks/itm/visualizations/info/hdrcnn.png" />
              <p class="label">HDRCNN, DeepHDR, ExpNet</p>
            </div>
            <div class="hhh">
              <img src="https://storage.videoprocessing.ai/benchmarks/itm/visualizations/info/singlehdr.png" />
              <p class="label">SingleHDR, HDRToolbox*</p>
            </div>
            <div class="hhh">
              <img src="https://storage.videoprocessing.ai/benchmarks/itm/visualizations/info/hdrtv.png" />
              <p class="label">HDRTVNet</p>
            </div>
            <div class="hhh">
              <img src="https://storage.videoprocessing.ai/benchmarks/itm/visualizations/info/gt.png" />
              <p class="label">GT</p>
            </div>
          </div>
          <style type="text/css">
            .kkk {
                display: flex;
                flex-direction: row;
                justify-content: center;
            }
            
            .hhh {
                display: flex;
                flex-direction: column;
                justify-content: flex-start;
                align-items: center;
                margin-left: 0.5em;
                margin-right: 0.5em;
            }
            
            .label {
                font-style: italic;
            }
          </style>
          <p><br />
            HDRToolbox* – a group of methods implemented in HDRToolbox: Akyuz, Kuo, Huo, HuoPhys, KovOliv</p>
          <p>This way we obtain a unified output of all methods (including GT) and then use the <a href="https://compression.ru/video/quality_measure/video_measurement_tool.html">MSU VQMT</a> utility and official metrics repositories to calculate the results.</p>
          <p>This stage is very important and if the pixel values are interpreted incorrectly, the metric values may be distorted, so you should include the detailed instruction for video rendering in your benchmark submission.</p>
        </div>
      </div>
      <div class="tiles-width meta">
        <div class="share">
          <link href="/assets/css/sharing-buttons.css" rel="stylesheet" type="text/css">
          <!-- Sharingbutton Twitter -->
          <a class="resp-sharing-button__link"
   href="https://twitter.com/intent/tweet/?text=MSU HDR Video Reconstruction Benchmark Methodology&amp;url=
http://localhost:4000/benchmarks/inverse-tone-mapping-methodology.html
"
   target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--twitter resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M23.44 4.83c-.8.37-1.5.38-2.22.02.93-.56.98-.96 1.32-2.02-.88.52-1.86.9-2.9 1.1-.82-.88-2-1.43-3.3-1.43-2.5 0-4.55 2.04-4.55 4.54 0 .36.03.7.1 1.04-3.77-.2-7.12-2-9.36-4.75-.4.67-.6 1.45-.6 2.3 0 1.56.8 2.95 2 3.77-.74-.03-1.44-.23-2.05-.57v.06c0 2.2 1.56 4.03 3.64 4.44-.67.2-1.37.2-2.06.08.58 1.8 2.26 3.12 4.25 3.16C5.78 18.1 3.37 18.74 1 18.46c2 1.3 4.4 2.04 6.97 2.04 8.35 0 12.92-6.92 12.92-12.93 0-.2 0-.4-.02-.6.9-.63 1.96-1.22 2.56-2.14z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton Telegram -->
          <a aria-label=""
   class="resp-sharing-button__link"
   href="https://telegram.me/share/url?text=MSU HDR Video Reconstruction Benchmark Methodology&amp;url=
http://localhost:4000/benchmarks/inverse-tone-mapping-methodology.html
" rel="noopener" target="_blank">
            <div class="resp-sharing-button resp-sharing-button--telegram resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M.707 8.475C.275 8.64 0 9.508 0 9.508s.284.867.718 1.03l5.09 1.897 1.986 6.38a1.102 1.102 0 0 0 1.75.527l2.96-2.41a.405.405 0 0 1 .494-.013l5.34 3.87a1.1 1.1 0 0 0 1.046.135 1.1 1.1 0 0 0 .682-.803l3.91-18.795A1.102 1.102 0 0 0 22.5.075L.706 8.475z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton Facebook -->
          <a aria-label=""
   class="resp-sharing-button__link"
   href="https://facebook.com/sharer/sharer.php?u=
http://localhost:4000/benchmarks/inverse-tone-mapping-methodology.html
" rel="noopener"
   target="_blank">
            <div class="resp-sharing-button resp-sharing-button--facebook resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M18.77 7.46H14.5v-1.9c0-.9.6-1.1 1-1.1h3V.5h-4.33C10.24.5 9.5 3.44 9.5 5.32v2.15h-3v4h3v12h5v-12h3.85l.42-4z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton E-Mail -->
          <a class="resp-sharing-button__link"
   href="mailto:?subject=MSU HDR Video Reconstruction Benchmark Methodology&amp;body=
http://localhost:4000/benchmarks/inverse-tone-mapping-methodology.html
" target="_self" rel="noopener"
   aria-label="">
            <div class="resp-sharing-button resp-sharing-button--email resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M22 4H2C.9 4 0 4.9 0 6v12c0 1.1.9 2 2 2h20c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zM7.25 14.43l-3.5 2c-.08.05-.17.07-.25.07-.17 0-.34-.1-.43-.25-.14-.24-.06-.55.18-.68l3.5-2c.24-.14.55-.06.68.18.14.24.06.55-.18.68zm4.75.07c-.1 0-.2-.03-.27-.08l-8.5-5.5c-.23-.15-.3-.46-.15-.7.15-.22.46-.3.7-.14L12 13.4l8.23-5.32c.23-.15.54-.08.7.15.14.23.07.54-.16.7l-8.5 5.5c-.08.04-.17.07-.27.07zm8.93 1.75c-.1.16-.26.25-.43.25-.08 0-.17-.02-.25-.07l-3.5-2c-.24-.13-.32-.44-.18-.68s.44-.32.68-.18l3.5 2c.24.13.32.44.18.68z"/>
              </svg>
            </div>
          </a>
          <!-- Sharingbutton LinkedIn -->
          <a class="resp-sharing-button__link"
   href="https://www.linkedin.com/shareArticle?mini=true&amp;url=
http://localhost:4000/benchmarks/inverse-tone-mapping-methodology.html
&amp;title=MSU HDR Video Reconstruction Benchmark Methodology&amp;summary=MSU HDR Video Reconstruction Benchmark Methodology&amp;source=
http://localhost:4000/benchmarks/inverse-tone-mapping-methodology.html
"
   target="_blank" rel="noopener" aria-label="">
            <div class="resp-sharing-button resp-sharing-button--linkedin resp-sharing-button--small">
              <svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
                <path d="M6.5 21.5h-5v-13h5v13zM4 6.5C2.5 6.5 1.5 5.3 1.5 4s1-2.4 2.5-2.4c1.6 0 2.5 1 2.6 2.5 0 1.4-1 2.5-2.6 2.5zm11.5 6c-1 0-2 1-2 2v7h-5v-13h5V10s1.6-1.5 4-1.5c3 0 5 2.2 5 6.3v6.7h-5v-7c0-1-1-2-2-2z"/>
              </svg>
            </div>
          </a>
        </div>
        <span class="date">10 May 2022</span>
      </div>
      <div class="tiles-width separator"></div>
      <div class="tiles-width see-also-title">
        See Also
      </div>
      <div class="tiles wide">
        <a class="tile" href="/benchmarks/deblurring.html">
          <div class="image" style="background-image: url(/assets/img/benchmarks/deblurring/preview.png)"></div>
          <div class="title">MSU Video Deblurring Benchmark 2022</div>
          <div class="text">Learn about the best video deblurring methods and choose the best model</div>
        </a>
        <a class="tile" href="/benchmarks/video-frame-interpolation.html">
          <div class="image" style="background-image: url(/assets/img/benchmarks/vfi/main.webp)"></div>
          <div class="title">MSU Video Frame Interpolation Benchmark 2022</div>
          <div class="text">Discover the best algorithm to make high-quality and smooth slow motion videos</div>
        </a>
      </div>
      <div class="tiles-width separator"></div>
      <div class="tiles-width markdown site-structure">
        <span class="title">Site structure</span>
        <ul>
          <li>
            <a href="/benchmarks/">MSU Benchmark Collection</a>
            <ul>
              <li><a href="/benchmarks/deblurring.html">MSU Video Deblurring Benchmark 2022</a></li>
              <li><a href="/benchmarks/video-frame-interpolation.html">MSU Video Frame Interpolation Benchmark 2022</a></li>
              <li><a href="/benchmarks/video-upscalers.html">MSU Video Upscalers Benchmark 2022</a></li>
              <li><a href="/benchmarks/inverse-tone-mapping.html">MSU HDR Video Reconstruction Benchmark 2022</a></li>
              <li><a href="/benchmarks/super-resolution-for-video-compression.html">MSU Super-Resolution for Video Compression Benchmark 2022</a></li>
              <li><a href="/benchmarks/no-reference-video-quality-metrics.html">MSU No-Reference Video Quality Metrics Benchmark 2022</a></li>
              <li><a href="/benchmarks/full-reference-video-quality-metrics.html">MSU Full-Reference Video Quality Metrics Benchmark 2022</a></li>
              <li><a href="/benchmarks/aligners.html">MSU Video Alignment and Retrieval Benchmark</a></li>
              <li><a href="/benchmarks/mobile-video-codec-benchmark.html">MSU Mobile Video Codecs Benchmark 2021</a></li>
              <li><a href="/benchmarks/video-super-resolution.html">MSU Video Super-Resolution Benchmark</a></li>
              <li><a href="/benchmarks/shot-boundary-detection.html">MSU Shot Boundary Detection Benchmark 2020</a></li>
              <li><a href="/benchmarks/deinterlacer.html">MSU Deinterlacer Benchmark</a></li>
              <li><a href="https://videomatting.com/" target="_blank">The VideoMatting Project</a></li>
              <li><a href="https://videocompletion.org/" target="_blank">Video Completion</a></li>
            </ul>
          </li>
          <li>
            <a href="/codecs/">Codecs Comparisons & Optimization</a>
            <ul>
              <li><a href="/codecs/avc/">AVC Codecs Comparison</a></li>
              <li><a href="/codecs/hevc/">HEVC Codecs Comparison</a></li>
              <li><a href="/codecs/image/">Image Codecs Comparison</a></li>
              <li><a href="/codecs/lossless/">Lossless Codecs Comparison</a></li>
              <li><a href="/codecs/optimization/">Codecs Optimization and Tuning</a></li>
              <li><a href="/codecs/reports/">All Codecs Comparison Reports</a></li>
            </ul>
          </li>
          <li>
            <a href="/vqmt/">VQMT</a>
            <ul>
              <li><a href="/vqmt/plugins/">VQMT Plugins</a></li>
            </ul>
          </li>
          <li>
            <a href="/stereo_quality/">Video Quality Measurement Tool 3D</a>
            <ul>
              <li><a href="/stereo_quality/correction/">Stereo Artifacts Correction</a></li>
              <li><a href="/stereo_quality/metrics/">Stereo Quality Metrics</a></li>
              <li><a href="/stereo_quality/reports/">All Stereo Quality Reports</a></li>
            </ul>
          </li>
          <li>
            <a href="/datasets/">MSU Datasets Collection</a>
            <ul>
            </ul>
          </li>
          <li>
            <a href="/metrics/">Metrics Research</a>
            <ul>
            </ul>
          </li>
          <li>
            <a href="/video_filters/">Video Filters</a>
            <ul>
              <li><a href="/video_filters/image/">Image Processing Filters</a></li>
              <li><a href="/video_filters/public/">Free Filters</a></li>
              <li><a href="/video_filters/virtualdub/">VirtualDub Filters</a></li>
            </ul>
          </li>
          <li>
            <a href="/other/">Other Projects</a>
            <ul>
            </ul>
          </li>
        </ul>
      </div>
    </div>
    <div class="footer">
      <div class="footer-column copyright">
        <img alt="MSU Graphics & Multimedia Lab Video Group" class="logo" src="/assets/img/logo.svg">
        <div class="text">
          MSU Graphics & Media Lab Video Group
          <br>
          2019&ndash;2022
        </div>
      </div>
      <div class="footer-column">
        <ul>
          <li><a href="/codecs/">Codecs Comparisons & Optimization</a></li>
          <li><a href="/vqmt/">VQMT</a></li>
          <li><a href="/stereo_quality/">Video Quality Measurement Tool 3D</a></li>
          <li><a href="/datasets/">MSU Datasets Collection</a></li>
          <li><a href="/metrics/">Metrics Research</a></li>
          <li><a href="/video_filters/">Video Filters</a></li>
          <li><a href="/other/">Other Projects</a></li>
        </ul>
      </div>
      <div class="footer-column">
        <ul>
          <li><a href="/about/">About Us</a></li>
          <li><a href="/benchmarks/">Benchmarks</a></li>
          <li><a href="/projects/">Projects</a></li>
          <li><a href="/publications/">Publications</a></li>
          <li><a href="/contacts/">Contacts</a></li>
        </ul>
      </div>
    </div>
  </body>
</html>